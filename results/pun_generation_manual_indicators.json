{
    "hom_231": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1682": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_787": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_979": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_348": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_714": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_393": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_531": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_587": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_554": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_872": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        }
    },
    "hom_547": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_780": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_434": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_630": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_555": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_451": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_588": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_374": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        }
    },
    "hom_1926": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1442": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1042": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1056": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1351": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_2116": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1906": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1013": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1345": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_847": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_402": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_100": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1628": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_383": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1807": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_206": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1006": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        }
    },
    "hom_1171": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_395": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_500": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_2150": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1969": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_1796": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_23": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_855": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        }
    },
    "hom_1990": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_202": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1942": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_2209": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1970": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_2237": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_323": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_14": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_1008": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        }
    },
    "hom_88": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_2160": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_2076": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1236": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_1066": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        }
    },
    "hom_1940": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_96": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_406": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_870": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_345": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_1441": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_109": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_7": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1737": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1381": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_1377": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_619": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1397": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_778": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_2083": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_568": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_914": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1486": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_234": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_582": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1107": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1720": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1558": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_83": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1983": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "hom_1941": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_1215": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_646": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        }
    },
    "hom_1870": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_727": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_2200": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1825": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_135": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_179": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_2081": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "hom_771": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_655": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_1433": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "hom_1450": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "hom_1726": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_9": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "hom_473": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_188": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 0,
                "funniness": 0
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1228": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1201": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_708": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_250": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_159": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 1,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1336": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1640": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        }
    },
    "het_1144": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1112": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_216": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1755": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1029": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1254": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_934": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1763": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_872": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1707": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_39": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_388": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_793": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_354": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_69": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1726": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_662": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1466": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1193": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1180": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_408": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1693": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_410": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1711": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1629": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1340": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1070": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1260": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_417": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_656": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1054": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1329": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_51": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_94": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        }
    },
    "het_292": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_751": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_905": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1090": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1654": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1637": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_459": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_978": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_822": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_386": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_990": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_305": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_754": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_428": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_387": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1194": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1486": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1050": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_501": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_458": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_810": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_64": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_434": {
        "human_text": {
            "success": 1,
            "coherence": 5,
            "funniness": 5
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 5
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 5
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 5
            }
        }
    },
    "het_1316": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_25": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_77": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_58": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_369": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 4
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1442": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_698": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_589": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_848": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_769": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_783": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1032": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1160": {
        "human_text": {
            "success": 0,
            "coherence": 4,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_306": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 2
            },
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_1427": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_791": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_268": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1195": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_247": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 4
            }
        }
    },
    "het_617": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_363": {
        "human_text": {
            "success": 0,
            "coherence": 3,
            "funniness": 1
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1027": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1078": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_900": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 4
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1450": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 1,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_1608": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1016": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 1,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_573": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1301": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        }
    },
    "het_619": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_1089": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    },
    "het_100": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 3
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 5,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 4,
                "funniness": 3
            }
        }
    },
    "het_1428": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        }
    },
    "het_1057": {
        "human_text": {
            "success": 1,
            "coherence": 3,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 1,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 1,
                "coherence": 4,
                "funniness": 2
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 1,
                "coherence": 5,
                "funniness": 3
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 1,
                "coherence": 3,
                "funniness": 2
            }
        }
    },
    "het_689": {
        "human_text": {
            "success": 1,
            "coherence": 4,
            "funniness": 2
        },
        "gpt-3.5-turbo-1106_text": {
            "method 0": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 2
            }
        },
        "gpt-4-1106-preview_text": {
            "method 1": {
                "success": 1,
                "coherence": 2,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "gemini-pro_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "vicuna-7b-v1.5_text": {
            "method 1": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "llama-2-7b-chat_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            }
        },
        "mistral-7b-instruct-v0.2_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "openchat-3.5-0106_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 2,
                "funniness": 1
            }
        },
        "claude-3-opus-20240229_text": {
            "method 1": {
                "success": 0,
                "coherence": 3,
                "funniness": 1
            },
            "method 2": {
                "success": 0,
                "coherence": 4,
                "funniness": 1
            }
        }
    }
}