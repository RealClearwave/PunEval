{
    "human_text": {
        "hom": {
            "avg_len": 12.0,
            "avg_ambiguity": 0.2246,
            "avg_distinctiveness": 0.1291,
            "avg_surprise": -0.0692,
            "avg_unusualness": 5.5692,
            "avg_incorp_pun": 0.9963,
            "avg_incorp_one_pun": 0.9901,
            "avg_incorp_contexts": null,
            "avg_overlap": 1.0,
            "avg_success": 0.86,
            "avg_strict_success": 0.0,
            "avg_coherence": 3.86,
            "avg_funniness": 3.26812221767772
        },
        "het": {
            "avg_len": 12.37,
            "avg_ambiguity": 0.1853,
            "avg_distinctiveness": 0.2558,
            "avg_surprise": 0.3229,
            "avg_unusualness": 5.8512,
            "avg_incorp_pun": 0.9907,
            "avg_incorp_one_pun": 0.9845,
            "avg_incorp_contexts": null,
            "avg_overlap": 1.0,
            "avg_success": 0.84,
            "avg_strict_success": 0.0,
            "avg_coherence": 3.86,
            "avg_funniness": 3.228916184549725
        }
    },
    "gpt-3.5-turbo-1106_text0": {
        "hom": {
            "avg_len": 11.38,
            "avg_ambiguity": 0.1948,
            "avg_distinctiveness": 0.0365,
            "avg_surprise": -0.6403,
            "avg_unusualness": 4.6064,
            "avg_incorp_pun": 0.9963,
            "avg_incorp_one_pun": 0.9827,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0776,
            "avg_success": 0.01,
            "avg_strict_success": 0.01,
            "avg_coherence": 4.01,
            "avg_funniness": 1.0422505058659501
        },
        "het": {
            "avg_len": 11.76,
            "avg_ambiguity": 0.1132,
            "avg_distinctiveness": 0.0705,
            "avg_surprise": -0.7344,
            "avg_unusualness": 4.5882,
            "avg_incorp_pun": 0.9938,
            "avg_incorp_one_pun": 0.9784,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0633,
            "avg_success": 0.01,
            "avg_strict_success": 0.01,
            "avg_coherence": 4.12,
            "avg_funniness": 1.0140279442228421
        }
    },
    "gpt-3.5-turbo-1106_text1": {
        "hom": {
            "avg_len": 14.9,
            "avg_ambiguity": 0.2195,
            "avg_distinctiveness": 0.0637,
            "avg_surprise": -0.2329,
            "avg_unusualness": 4.8936,
            "avg_incorp_pun": 0.8753,
            "avg_incorp_one_pun": 0.7136,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.1033,
            "avg_success": 0.42,
            "avg_strict_success": 0.42,
            "avg_coherence": 3.32,
            "avg_funniness": 1.3667025924290976
        },
        "het": {
            "avg_len": 12.26,
            "avg_ambiguity": 0.2234,
            "avg_distinctiveness": 0.0733,
            "avg_surprise": 0.0721,
            "avg_unusualness": 5.3832,
            "avg_incorp_pun": 0.966,
            "avg_incorp_one_pun": 0.5209,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0947,
            "avg_success": 0.29,
            "avg_strict_success": 0.28,
            "avg_coherence": 3.06,
            "avg_funniness": 1.3058687178116577
        }
    },
    "gpt-3.5-turbo-1106_text2": {
        "hom": {
            "avg_len": 12.22,
            "avg_ambiguity": 0.217,
            "avg_distinctiveness": 0.0787,
            "avg_surprise": -0.0761,
            "avg_unusualness": 5.5059,
            "avg_incorp_pun": 0.9926,
            "avg_incorp_one_pun": 0.8556,
            "avg_incorp_contexts": 0.9522,
            "avg_overlap": 0.1831,
            "avg_success": 0.55,
            "avg_strict_success": 0.5,
            "avg_coherence": 3.46,
            "avg_funniness": 2.1366816765699044
        },
        "het": {
            "avg_len": 12.03,
            "avg_ambiguity": 0.216,
            "avg_distinctiveness": 0.1634,
            "avg_surprise": 0.2053,
            "avg_unusualness": 5.7671,
            "avg_incorp_pun": 0.9876,
            "avg_incorp_one_pun": 0.5425,
            "avg_incorp_contexts": 0.9367,
            "avg_overlap": 0.1357,
            "avg_success": 0.32,
            "avg_strict_success": 0.31,
            "avg_coherence": 3.26,
            "avg_funniness": 1.6986112577543748
        }
    },
    "gpt-4-1106-preview_text1": {
        "hom": {
            "avg_len": 13.96,
            "avg_ambiguity": 0.2247,
            "avg_distinctiveness": 0.0474,
            "avg_surprise": -0.0269,
            "avg_unusualness": 5.2766,
            "avg_incorp_pun": 0.9802,
            "avg_incorp_one_pun": 0.8901,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0837,
            "avg_success": 0.6,
            "avg_strict_success": 0.6,
            "avg_coherence": 3.49,
            "avg_funniness": 2.0159396274866155
        },
        "het": {
            "avg_len": 12.22,
            "avg_ambiguity": 0.2208,
            "avg_distinctiveness": 0.0977,
            "avg_surprise": 0.1205,
            "avg_unusualness": 5.7045,
            "avg_incorp_pun": 0.9799,
            "avg_incorp_one_pun": 0.847,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0831,
            "avg_success": 0.51,
            "avg_strict_success": 0.51,
            "avg_coherence": 3.43,
            "avg_funniness": 1.9478532147202203
        }
    },
    "gpt-4-1106-preview_text2": {
        "hom": {
            "avg_len": 13.01,
            "avg_ambiguity": 0.2169,
            "avg_distinctiveness": 0.0815,
            "avg_surprise": -0.2174,
            "avg_unusualness": 5.4715,
            "avg_incorp_pun": 0.9951,
            "avg_incorp_one_pun": 0.8802,
            "avg_incorp_contexts": 0.9764,
            "avg_overlap": 0.1815,
            "avg_success": 0.67,
            "avg_strict_success": 0.62,
            "avg_coherence": 3.64,
            "avg_funniness": 2.583763249080273
        },
        "het": {
            "avg_len": 11.88,
            "avg_ambiguity": 0.1992,
            "avg_distinctiveness": 0.1684,
            "avg_surprise": 0.2845,
            "avg_unusualness": 5.8005,
            "avg_incorp_pun": 0.983,
            "avg_incorp_one_pun": 0.7944,
            "avg_incorp_contexts": 0.9689,
            "avg_overlap": 0.1438,
            "avg_success": 0.6,
            "avg_strict_success": 0.57,
            "avg_coherence": 3.59,
            "avg_funniness": 2.348253358884639
        }
    },
    "gemini-pro_text1": {
        "hom": {
            "avg_len": 13.13,
            "avg_ambiguity": 0.2224,
            "avg_distinctiveness": 0.0376,
            "avg_surprise": -0.203,
            "avg_unusualness": 5.2255,
            "avg_incorp_pun": 0.9642,
            "avg_incorp_one_pun": 0.6802,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.091,
            "avg_success": 0.32,
            "avg_strict_success": 0.32,
            "avg_coherence": 3.52,
            "avg_funniness": 1.6986112577543748
        },
        "het": {
            "avg_len": 10.46,
            "avg_ambiguity": 0.2406,
            "avg_distinctiveness": 0.0721,
            "avg_surprise": -0.0756,
            "avg_unusualness": 5.8053,
            "avg_incorp_pun": 0.9845,
            "avg_incorp_one_pun": 0.3833,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0904,
            "avg_success": 0.15,
            "avg_strict_success": 0.14,
            "avg_coherence": 3.33,
            "avg_funniness": 1.3361867351124677
        }
    },
    "gemini-pro_text2": {
        "hom": {
            "avg_len": 11.15,
            "avg_ambiguity": 0.2208,
            "avg_distinctiveness": 0.079,
            "avg_surprise": -0.2003,
            "avg_unusualness": 5.6905,
            "avg_incorp_pun": 0.9951,
            "avg_incorp_one_pun": 0.6889,
            "avg_incorp_contexts": 0.9456,
            "avg_overlap": 0.1679,
            "avg_success": 0.44,
            "avg_strict_success": 0.41,
            "avg_coherence": 3.47,
            "avg_funniness": 1.8804401412077731
        },
        "het": {
            "avg_len": 10.41,
            "avg_ambiguity": 0.1981,
            "avg_distinctiveness": 0.1488,
            "avg_surprise": 0.1421,
            "avg_unusualness": 6.0668,
            "avg_incorp_pun": 0.9845,
            "avg_incorp_one_pun": 0.5811,
            "avg_incorp_contexts": 0.9239,
            "avg_overlap": 0.1345,
            "avg_success": 0.33,
            "avg_strict_success": 0.32,
            "avg_coherence": 3.46,
            "avg_funniness": 1.7312763704847067
        }
    },
    "vicuna-7b-v1.5_text1": {
        "hom": {
            "avg_len": 15.89,
            "avg_ambiguity": 0.2227,
            "avg_distinctiveness": 0.0616,
            "avg_surprise": -0.2488,
            "avg_unusualness": 4.7341,
            "avg_incorp_pun": 0.9679,
            "avg_incorp_one_pun": 0.6901,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0832,
            "avg_success": 0.12,
            "avg_strict_success": 0.12,
            "avg_coherence": 3.44,
            "avg_funniness": 1.2161215279823918
        },
        "het": {
            "avg_len": 15.29,
            "avg_ambiguity": 0.2111,
            "avg_distinctiveness": 0.0881,
            "avg_surprise": -0.2721,
            "avg_unusualness": 5.0302,
            "avg_incorp_pun": 0.983,
            "avg_incorp_one_pun": 0.3771,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0772,
            "avg_success": 0.05,
            "avg_strict_success": 0.05,
            "avg_coherence": 3.21,
            "avg_funniness": 1.1282285803911791
        }
    },
    "vicuna-7b-v1.5_text2": {
        "hom": {
            "avg_len": 15.1,
            "avg_ambiguity": 0.1991,
            "avg_distinctiveness": 0.0766,
            "avg_surprise": -0.1806,
            "avg_unusualness": 5.1716,
            "avg_incorp_pun": 0.984,
            "avg_incorp_one_pun": 0.7815,
            "avg_incorp_contexts": 0.8848,
            "avg_overlap": 0.1305,
            "avg_success": 0.3,
            "avg_strict_success": 0.29,
            "avg_coherence": 3.45,
            "avg_funniness": 1.6499487420084802
        },
        "het": {
            "avg_len": 15.77,
            "avg_ambiguity": 0.1824,
            "avg_distinctiveness": 0.2375,
            "avg_surprise": 0.0154,
            "avg_unusualness": 5.3241,
            "avg_incorp_pun": 0.9876,
            "avg_incorp_one_pun": 0.4529,
            "avg_incorp_contexts": 0.8697,
            "avg_overlap": 0.1094,
            "avg_success": 0.21,
            "avg_strict_success": 0.21,
            "avg_coherence": 3.34,
            "avg_funniness": 1.45941838818939
        }
    },
    "llama-2-7b-chat_text1": {
        "hom": {
            "avg_len": 17.65,
            "avg_ambiguity": 0.2058,
            "avg_distinctiveness": 0.0334,
            "avg_surprise": -0.1296,
            "avg_unusualness": 4.9223,
            "avg_incorp_pun": 0.658,
            "avg_incorp_one_pun": 0.4247,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0746,
            "avg_success": 0.06,
            "avg_strict_success": 0.06,
            "avg_coherence": 3.15,
            "avg_funniness": 1.0706931364657333
        },
        "het": {
            "avg_len": 14.32,
            "avg_ambiguity": 0.168,
            "avg_distinctiveness": 0.1548,
            "avg_surprise": -0.0292,
            "avg_unusualness": 5.5593,
            "avg_incorp_pun": 0.4606,
            "avg_incorp_one_pun": 0.1453,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0659,
            "avg_success": 0.04,
            "avg_strict_success": 0.04,
            "avg_coherence": 2.73,
            "avg_funniness": 1.0422505058659501
        }
    },
    "llama-2-7b-chat_text2": {
        "hom": {
            "avg_len": 17.39,
            "avg_ambiguity": 0.2052,
            "avg_distinctiveness": 0.1074,
            "avg_surprise": -0.0932,
            "avg_unusualness": 5.2542,
            "avg_incorp_pun": 0.8741,
            "avg_incorp_one_pun": 0.6049,
            "avg_incorp_contexts": 0.7455,
            "avg_overlap": 0.105,
            "avg_success": 0.34,
            "avg_strict_success": 0.34,
            "avg_coherence": 3.28,
            "avg_funniness": 1.601692898202212
        },
        "het": {
            "avg_len": 17.49,
            "avg_ambiguity": 0.18,
            "avg_distinctiveness": 0.2348,
            "avg_surprise": -0.0658,
            "avg_unusualness": 5.3981,
            "avg_incorp_pun": 0.9057,
            "avg_incorp_one_pun": 0.3524,
            "avg_incorp_contexts": 0.7559,
            "avg_overlap": 0.0967,
            "avg_success": 0.22,
            "avg_strict_success": 0.22,
            "avg_coherence": 3.15,
            "avg_funniness": 1.412843173336284
        }
    },
    "mistral-7b-instruct-v0.2_text1": {
        "hom": {
            "avg_len": 18.45,
            "avg_ambiguity": 0.1932,
            "avg_distinctiveness": 0.0722,
            "avg_surprise": -0.2389,
            "avg_unusualness": 5.2996,
            "avg_incorp_pun": 0.9741,
            "avg_incorp_one_pun": 0.5827,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0897,
            "avg_success": 0.17,
            "avg_strict_success": 0.17,
            "avg_coherence": 3.26,
            "avg_funniness": 1.321002875427849
        },
        "het": {
            "avg_len": 14.55,
            "avg_ambiguity": 0.2114,
            "avg_distinctiveness": 0.1511,
            "avg_surprise": -0.1564,
            "avg_unusualness": 5.8437,
            "avg_incorp_pun": 0.9722,
            "avg_incorp_one_pun": 0.3431,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0723,
            "avg_success": 0.13,
            "avg_strict_success": 0.13,
            "avg_coherence": 3.23,
            "avg_funniness": 1.3361867351124677
        }
    },
    "mistral-7b-instruct-v0.2_text2": {
        "hom": {
            "avg_len": 16.62,
            "avg_ambiguity": 0.1861,
            "avg_distinctiveness": 0.1145,
            "avg_surprise": -0.2009,
            "avg_unusualness": 5.3947,
            "avg_incorp_pun": 0.9877,
            "avg_incorp_one_pun": 0.616,
            "avg_incorp_contexts": 0.9236,
            "avg_overlap": 0.1096,
            "avg_success": 0.28,
            "avg_strict_success": 0.28,
            "avg_coherence": 3.4,
            "avg_funniness": 1.617732675916789
        },
        "het": {
            "avg_len": 15.41,
            "avg_ambiguity": 0.1755,
            "avg_distinctiveness": 0.213,
            "avg_surprise": 0.1078,
            "avg_unusualness": 5.6295,
            "avg_incorp_pun": 0.9892,
            "avg_incorp_one_pun": 0.3725,
            "avg_incorp_contexts": 0.9174,
            "avg_overlap": 0.111,
            "avg_success": 0.22,
            "avg_strict_success": 0.22,
            "avg_coherence": 3.29,
            "avg_funniness": 1.506422236416429
        }
    },
    "openchat-3.5-0106_text1": {
        "hom": {
            "avg_len": 16.41,
            "avg_ambiguity": 0.2082,
            "avg_distinctiveness": 0.058,
            "avg_surprise": -0.168,
            "avg_unusualness": 5.0549,
            "avg_incorp_pun": 0.9765,
            "avg_incorp_one_pun": 0.5494,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.1014,
            "avg_success": 0.2,
            "avg_strict_success": 0.2,
            "avg_coherence": 3.24,
            "avg_funniness": 1.260766934373971
        },
        "het": {
            "avg_len": 13.62,
            "avg_ambiguity": 0.2071,
            "avg_distinctiveness": 0.1356,
            "avg_surprise": -0.261,
            "avg_unusualness": 5.5112,
            "avg_incorp_pun": 0.9845,
            "avg_incorp_one_pun": 0.2705,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0847,
            "avg_success": 0.08,
            "avg_strict_success": 0.08,
            "avg_coherence": 3.05,
            "avg_funniness": 1.1282285803911791
        }
    },
    "openchat-3.5-0106_text2": {
        "hom": {
            "avg_len": 15.6,
            "avg_ambiguity": 0.1957,
            "avg_distinctiveness": 0.0905,
            "avg_surprise": -0.133,
            "avg_unusualness": 5.3523,
            "avg_incorp_pun": 0.9901,
            "avg_incorp_one_pun": 0.6358,
            "avg_incorp_contexts": 0.9602,
            "avg_overlap": 0.1225,
            "avg_success": 0.37,
            "avg_strict_success": 0.37,
            "avg_coherence": 3.35,
            "avg_funniness": 1.7149215928310166
        },
        "het": {
            "avg_len": 14.24,
            "avg_ambiguity": 0.1655,
            "avg_distinctiveness": 0.2352,
            "avg_surprise": 0.0127,
            "avg_unusualness": 5.5161,
            "avg_incorp_pun": 0.9954,
            "avg_incorp_one_pun": 0.3524,
            "avg_incorp_contexts": 0.9382,
            "avg_overlap": 0.1114,
            "avg_success": 0.24,
            "avg_strict_success": 0.24,
            "avg_coherence": 3.21,
            "avg_funniness": 1.5221844318998505
        }
    },
    "claude-3-opus-20240229_text1": {
        "hom": {
            "avg_len": 11.24,
            "avg_ambiguity": 0.211,
            "avg_distinctiveness": 0.0727,
            "avg_surprise": -0.1501,
            "avg_unusualness": 5.6868,
            "avg_incorp_pun": 0.9247,
            "avg_incorp_one_pun": 0.8926,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.1031,
            "avg_success": 0.54,
            "avg_strict_success": 0.54,
            "avg_coherence": 3.58,
            "avg_funniness": 2.0502322450466735
        },
        "het": {
            "avg_len": 9.35,
            "avg_ambiguity": 0.2001,
            "avg_distinctiveness": 0.2077,
            "avg_surprise": 0.0964,
            "avg_unusualness": 6.578,
            "avg_incorp_pun": 0.9892,
            "avg_incorp_one_pun": 0.915,
            "avg_incorp_contexts": null,
            "avg_overlap": 0.0818,
            "avg_success": 0.47,
            "avg_strict_success": 0.46,
            "avg_coherence": 3.41,
            "avg_funniness": 1.9309364276944523
        }
    },
    "claude-3-opus-20240229_text2": {
        "hom": {
            "avg_len": 9.9,
            "avg_ambiguity": 0.2367,
            "avg_distinctiveness": 0.0811,
            "avg_surprise": -0.131,
            "avg_unusualness": 5.8319,
            "avg_incorp_pun": 0.9975,
            "avg_incorp_one_pun": 0.9074,
            "avg_incorp_contexts": 0.9719,
            "avg_overlap": 0.239,
            "avg_success": 0.65,
            "avg_strict_success": 0.53,
            "avg_coherence": 3.69,
            "avg_funniness": 2.4380719943279594
        },
        "het": {
            "avg_len": 9.57,
            "avg_ambiguity": 0.2062,
            "avg_distinctiveness": 0.185,
            "avg_surprise": 0.2747,
            "avg_unusualness": 6.2025,
            "avg_incorp_pun": 0.9923,
            "avg_incorp_one_pun": 0.8485,
            "avg_incorp_contexts": 0.9727,
            "avg_overlap": 0.1663,
            "avg_success": 0.61,
            "avg_strict_success": 0.55,
            "avg_coherence": 3.67,
            "avg_funniness": 2.348253358884639
        }
    }
}