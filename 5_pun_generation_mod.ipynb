{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Generation Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.562386Z",
     "start_time": "2024-03-27T15:16:20.462214Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from _api_key import get_deepseek_api_key\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Basic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.649565Z",
     "start_time": "2024-03-27T15:16:20.477229Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Load json file\n",
    "    \"\"\"\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        file = json.load(f)\n",
    "        f.close()\n",
    "    return file\n",
    "\n",
    "def save_json_file(file, file_path, sort_keys:bool=False):\n",
    "    \"\"\"\n",
    "    Save json file\n",
    "    \"\"\"\n",
    "    with open(file_path,'w',encoding='utf-8') as f:\n",
    "        json.dump(file, f, indent=4, ensure_ascii=False, sort_keys=sort_keys)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.649565Z",
     "start_time": "2024-03-27T15:16:20.492871Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitDataset(file, puntype='hom'):\n",
    "    \"\"\"\n",
    "    Enter path or json file to separate the pun part from the non-pun part of the dataset\n",
    "    \"\"\"\n",
    "    if isinstance(file,str):\n",
    "        dataset = load_json_file(file)\n",
    "    else:\n",
    "        dataset = file\n",
    "    punDataset = dict()\n",
    "    nonpunDataset = dict()\n",
    "    for ID in dataset:\n",
    "        data = dataset[ID]\n",
    "        if puntype in ID:\n",
    "            if data.get('pun_word', False):\n",
    "                punDataset[ID] = data\n",
    "            else:\n",
    "                nonpunDataset[ID] = data\n",
    "    return punDataset, nonpunDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.649565Z",
     "start_time": "2024-03-27T15:16:20.508491Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_human_pun(pun_dataset, save:bool=False, path_gen='pun_generation.json'):\n",
    "    \"\"\"\n",
    "    Add human-written puns\n",
    "    \"\"\"\n",
    "    path_gen = './results/' + path_gen\n",
    "    if os.path.exists(path_gen):\n",
    "        pun_generation = load_json_file(path_gen)\n",
    "    else:\n",
    "        pun_generation = dict()\n",
    "    for ID in pun_dataset:\n",
    "        data = pun_dataset[ID]\n",
    "        human_text = data['human_text']\n",
    "        if ID not in pun_generation:\n",
    "            pun_generation[ID] = {'human_text':human_text}\n",
    "        else:\n",
    "            pun_generation[ID].update({'human_text':human_text})\n",
    "    if save:\n",
    "        save_json_file(pun_generation, path_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Function of Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.649565Z",
     "start_time": "2024-03-27T15:16:20.524152Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_llm_to_generate(model, dataset, model_name:str=None, method:int=0, examples:dict=None,\n",
    "                         save:bool=False, path_gen='pun_generation.json', batch_size:int=1):\n",
    "    \"\"\"\n",
    "    Try generating puns with llm  \\n\n",
    "    method=0: Generate non-pun sentence with only a single layer of meaning \\n\n",
    "    method=1: Given pun pair, generate pun directly \\n\n",
    "    method=2: Given specific contextual word set, generate pun directly  \\n\n",
    "    \"\"\"\n",
    "    def parse_output(ID, output:str):\n",
    "        # Parse output and get the result\n",
    "        try:\n",
    "            output = output[output.index('{'): output.index('}')+1]\n",
    "        except:\n",
    "            output = output\n",
    "        try:\n",
    "            output = eval(output)\n",
    "            sentence = output['Sentence']\n",
    "        except:\n",
    "            # print(ID, output)\n",
    "            try:\n",
    "                sentence = output.split('Sentence')[-1]\n",
    "            except:\n",
    "                sentence = 'No correctly parsed result.'\n",
    "        return sentence\n",
    "\n",
    "    def get_punchline_elements(data:dict):\n",
    "        # Get pun word/sense, alternative word/sense, etc. from data\n",
    "        pun_word = data['pun_word']\n",
    "        pun_sense = data['pun_sense']\n",
    "        alter_word = data['alter_word']\n",
    "        alter_sense = data['alter_sense']\n",
    "        context_words = data['human_keywords']\n",
    "        return pun_word, pun_sense, alter_word, alter_sense, context_words\n",
    "\n",
    "    def extend_dict(given_dict, keys):\n",
    "        # Create a null value based on the keys\n",
    "        temp = given_dict\n",
    "        for key in keys:\n",
    "            if key not in temp:\n",
    "                temp[key] = dict()\n",
    "            temp = temp[key]\n",
    "        return given_dict\n",
    "\n",
    "    assert method in [0, 1, 2]\n",
    "    path_gen = './results/' + path_gen\n",
    "    if os.path.exists(path_gen):\n",
    "        record_gen = load_json_file(path_gen)\n",
    "    else:\n",
    "        record_gen = dict()\n",
    "    # [A]. Construct the prompt\n",
    "    definition = \"\"\"<*Definition*>\\nPuns are a form of wordplay exploiting different meanings of a word or similar-sounding words, while non-puns are jokes or statements that don't rely on such linguistic ambiguities.\\n\\n\"\"\"\n",
    "    # Method=0: Generate non-pun that only expresses one sense\n",
    "    if method == 0:\n",
    "        instruction = \"\"\"<*Instruction*>\\nBelow is a keyword and one of its meanings. Please generate a non-pun sentence with the keyword that conveys the given meaning. You must output the current status in a parsable JSON format. An example output looks like:\\n{{\"Sentence\": \"XXX\"}}\"\"\"\n",
    "        examples_string = \"\"\"\"\"\"\n",
    "        testing = \"\"\"\\n\\n<*Your Response*>\\nKeyword: {punchline}\\nMeaning: {pun_word} <{pun_sense}>\\nOutput:\"\"\"\n",
    "    # Method=1: Generate pun directly\n",
    "    elif method == 1:\n",
    "        instruction = \"\"\"<*Instruction*>\\nBelow is a keyword and two of its meanings. Please generate a pun sentence with punchline on the keyword that conveys both given meanings simultaneously. Except for the keyword, the pun sentence must not utilize any words from either of the two meanings. Besides, once a keyword is used, it's strictly prohibited to use it again in the latter half of the sentence.\\nYou must output the current status in a parsable JSON format. An example output looks like:\\n{{\"Sentence\": \"XXX\"}}\"\"\"\n",
    "        if examples is not None:\n",
    "            examples_temp = []\n",
    "            for ID in examples:\n",
    "                example = examples[ID]\n",
    "                pun_word, pun_sense, alter_word, alter_sense, context_words = get_punchline_elements(data=example)\n",
    "                punchline, text = example['punchline'], example['human_text']\n",
    "                examples_temp.append(f\"Keyword: {punchline}\\n\"\n",
    "                                     f\"Meaning 1: {pun_word} <{pun_sense}>\\n\"\n",
    "                                     f\"Meaning 2: {alter_word} <{alter_sense}>\\n\"\n",
    "                                     f\"Output:\\n{{{{\\\"Sentence\\\": \\\"{text}\\\"}}}}\")\n",
    "            examples_string = '\\n\\n<*Examples*>\\n' + '\\n\\n'.join(examples_temp)\n",
    "        else:\n",
    "            examples_string = \"\"\"\"\"\"\n",
    "        testing = \"\"\"\\n\\n<*Your Response*>\\nKeyword: {punchline}\\nMeaning 1: {pun_word} <{pun_sense}>\\nMeaning 2: {alter_word} <{alter_sense}>\\nOutput:\"\"\"\n",
    "    # Method=2: Generate puns directly based on specific contextual words\n",
    "    else:\n",
    "        instruction = \"\"\"<*Instruction*>\\nBelow is a keyword, two of its meanings and a set of contextual words. Please generate a pun sentence with punchline on the keyword that conveys both given meanings simultaneously and using all the contextual words. Except for the keyword, the pun sentence must not utilize any words from either of the two meanings. Besides, once a keyword is used, it's strictly prohibited to use it again in the latter half of the sentence.\\nYou must output the current status in a parsable JSON format. An example output looks like:\\n{{\"Sentence\": \"XXX\"}}\"\"\"\n",
    "        if examples is not None:\n",
    "            examples_temp = []\n",
    "            for ID in examples:\n",
    "                example = examples[ID]\n",
    "                pun_word, pun_sense, alter_word, alter_sense, context_words = get_punchline_elements(data=example)\n",
    "                punchline, text = example['punchline'], example['human_text']\n",
    "                examples_temp.append(f\"Keyword: {punchline}\\n\"\n",
    "                                     f\"Meaning 1: {pun_word} <{pun_sense}>\\n\"\n",
    "                                     f\"Meaning 2: {alter_word} <{alter_sense}>\\n\"\n",
    "                                     f\"Contextual Words: {', '.join(context_words)}.\\n\"\n",
    "                                     f\"Output:\\n{{{{\\\"Sentence\\\": \\\"{text}\\\"}}}}\")\n",
    "            examples_string = '\\n\\n<*Examples*>\\n' + '\\n\\n'.join(examples_temp)\n",
    "        else:\n",
    "            examples_string = \"\"\"\"\"\"\n",
    "        testing = \"\"\"\\n\\n<*Your Response*>\\nKeyword: {punchline}\\nMeaning 1: {pun_word} <{pun_sense}>\\nMeaning 2: {alter_word} <{alter_sense}>\\nContextual Words: {context_words}.\\nOutput:\"\"\"\n",
    "    # Combine all parts together\n",
    "    prompt_string = definition + instruction + examples_string + testing\n",
    "\n",
    "    # [B]. Call llm to generate\n",
    "    key_gen = f\"{model_name}_text\"\n",
    "    IDs = list(dataset.keys())\n",
    "    IDs_loaded = []\n",
    "    for ID in record_gen:\n",
    "        if record_gen[ID].get(key_gen, False) and \\\n",
    "           record_gen[ID][key_gen].get(f'method {method}', False):\n",
    "            IDs_loaded.append(ID)\n",
    "    all_ind = list(range(0,len(IDs)))\n",
    "    batch_ind = list(range(0,len(IDs),batch_size))\n",
    "    for ind in tqdm(all_ind):\n",
    "        if ind not in batch_ind:\n",
    "            continue\n",
    "        IDs_batch = IDs[ind: ind+batch_size]\n",
    "        # Remove the data that has already been run\n",
    "        IDs_batch = list(set(IDs_batch)-set(IDs_loaded))\n",
    "        if len(IDs_batch) == 0:\n",
    "            continue\n",
    "        _inputs = []\n",
    "        _human_text = []\n",
    "        for ID in IDs_batch:\n",
    "            data = dataset[ID]\n",
    "            pun_ind = int(data['pun_word_ind'].split('_')[-1]) - 1\n",
    "            punchline = data['human_text'].split(' ')[pun_ind]\n",
    "            pun_word, pun_sense, alter_word, alter_sense, context_words = get_punchline_elements(data=data)\n",
    "            _inputs.append(prompt_string.format(pun_word=pun_word, pun_sense=pun_sense,\n",
    "                                                alter_word=alter_word, alter_sense=alter_sense,\n",
    "                                                punchline=punchline, context_words=', '.join(context_words)))\n",
    "            _human_text.append(data['human_text'])\n",
    "\n",
    "        #_outputs = [out.content for out in model.batch(_inputs)]\n",
    "        _outputs = []\n",
    "        for i in range(len(_inputs)):\n",
    "            print(f'case {ind}, {i}:')\n",
    "            print(f'human text: {_human_text[i]}')\n",
    "            if 'deepseek' in model_name:\n",
    "                response = model.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": _inputs[i]},\n",
    "                    ],\n",
    "                    stream=False\n",
    "                )\n",
    "                \n",
    "                #decode response JSON\n",
    "                output = (json.loads(response.choices[0].message.content))['Sentence']\n",
    "                print(f'LLM output: {output}')\n",
    "                _outputs.append(output)\n",
    "            elif 'qwen2' in model_name:\n",
    "                url = \"http://localhost:1234/v1/chat/completions\"\n",
    "                headers = {\"Content-Type\": \"application/json\"}\n",
    "                payload = {\n",
    "                    \"model\": model_name,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"user\", \"content\": _inputs[i]},\n",
    "                    ],\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_tokens\": -1,\n",
    "                    \"stream\": False\n",
    "                }\n",
    "\n",
    "                response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "                response = response.json()\n",
    "                try:\n",
    "                    output = json.loads(response['choices'][0]['message']['content'])['Sentence']\n",
    "                except (KeyError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error parsing response: {e}\")\n",
    "                    output = response['choices'][0]['message']['content']\n",
    "                print(f'LLM output: {output}')\n",
    "                _outputs.append(output)\n",
    "        \n",
    "        # print(_inputs[0][0].content)\n",
    "        # print(_outputs[0])\n",
    "        # break\n",
    "        for ID,out in zip(IDs_batch, _outputs):\n",
    "            sentence = parse_output(ID, out)\n",
    "            record_gen = extend_dict(record_gen, [ID, key_gen])\n",
    "            record_gen[ID][key_gen].update({f'method {method}': sentence})\n",
    "        if save:\n",
    "            save_json_file(record_gen, path_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.649565Z",
     "start_time": "2024-03-27T15:16:20.539744Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hom_path = r'./dataset/hom_dataset.json'\n",
    "het_path = r'./dataset/het_dataset.json'\n",
    "hom_punDataset, hom_nonpunDataset = splitDataset(hom_path)\n",
    "het_punDataset, het_nonpunDataset = splitDataset(het_path, puntype='het')\n",
    "\n",
    "# add_human_pun(dict(**hom_punDataset, **het_punDataset), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T15:16:20.662582Z",
     "start_time": "2024-03-27T15:16:20.555373Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose data from examples manually\n",
    "hom_examples = {\n",
    "    \"hom_705\":{\n",
    "        \"pun_word\": \"toll\",\n",
    "        \"pun_sense\": \"a fee levied for the use of roads or bridges (used for maintenance)\",\n",
    "        \"alter_word\": \"toll\",\n",
    "        \"alter_sense\": \"value measured by what must be given or done or undergone to obtain something\",\n",
    "        \"punchline\": \"toll\",\n",
    "        \"human_text\":\"Driving on so many turnpikes was taking its toll.\",\n",
    "        \"human_keywords\": [\"Driving\", \"many\", \"turnpikes\", \"taking its toll\"],\n",
    "    },\n",
    "    \"hom_488\":{\n",
    "        \"pun_word\": \"bore\",\n",
    "        \"pun_sense\": \"make a hole, especially with a pointed power or hand tool\",\n",
    "        \"alter_word\": \"bore\",\n",
    "        \"alter_sense\": \"cause to be bored\",\n",
    "        \"punchline\": \"bored\",\n",
    "        \"human_text\":\"A carpenter sat on his drill and was bored to tears.\",\n",
    "        \"human_keywords\": [\"carpenter\", \"sat\", \"drill\", \"bored to tears\"],\n",
    "    },\n",
    "    \"hom_1556\":{\n",
    "        \"pun_word\": \"foil\",\n",
    "        \"pun_sense\": \"a piece of thin and flexible sheet metal\",\n",
    "        \"alter_word\": \"foil\",\n",
    "        \"alter_sense\": \"hinder or prevent (the efforts, plans, or desires) of\",\n",
    "        \"punchline\": \"foiled\",\n",
    "        \"human_text\":\"One leftover said to another 'foiled again.'\",\n",
    "        \"human_keywords\": [\"leftover\", \"foiled\", \"again\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "het_examples = {\n",
    "    \"het_633\": {\n",
    "        \"pun_word\": \"sagely\",\n",
    "        \"pun_sense\": \"in a wise manner\",\n",
    "        \"alter_word\": \"sage\",\n",
    "        \"alter_sense\": \"aromatic fresh or dried grey-green leaves used widely as seasoning for meats and fowl and game etc\",\n",
    "        \"punchline\": \"sagely\",\n",
    "        \"human_text\": \"This fowl has been stuffed, said Tom sagely.\",\n",
    "        \"human_keywords\": [\"fowl\", \"stuffed\", \"sagely\"],\n",
    "    },\n",
    "    \"het_530\": {\n",
    "        \"pun_word\": \"toll\",\n",
    "        \"pun_sense\": \"ring slowly\",\n",
    "        \"alter_word\": \"tell off\",\n",
    "        \"alter_sense\": \"reprimand\",\n",
    "        \"punchline\": \"tolled\",\n",
    "        \"human_text\": \"A tangled bell ringer tolled himself off.\",\n",
    "        \"human_keywords\": [\"tangled\", \"bell ringer\", \"tolled himself off\"],\n",
    "    },\n",
    "    \"het_325\": {\n",
    "        \"pun_word\": \"c\",\n",
    "        \"pun_sense\": \"the 3rd letter of the Roman alphabet\",\n",
    "        \"alter_word\": \"sea\",\n",
    "        \"alter_sense\": \"a division of an ocean or a large body of salt water partially enclosed by land\",\n",
    "        \"punchline\": \"c\",\n",
    "        \"human_text\": \"An illiterate fisherman was lost at c.\",\n",
    "        \"human_keywords\": [\"illiterate\", \"fisherman\", \"c\"],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSeek-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DeepSeek-v3\n",
    "deepseek_name = 'deepseek-chat'\n",
    "temperature = 0.7\n",
    "deepseek_api_key = get_deepseek_api_key()  # use your api key\n",
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/810 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 0, 0:\n",
      "human text: Getting this job managing a country estate has put me off fried eggs . I ' m a gamekeeper turned poacher .\n",
      "LLM output: The gamekeeper caught the fried eggs poacher.\n",
      "case 0, 1:\n",
      "human text: The intelligent entrepreneur ' s idea for designing catapults meant that his boss was completely thrown .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/810 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generation method 2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcall_llm_to_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepseek\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepseek_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_punDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m call_llm_to_generate(model\u001b[38;5;241m=\u001b[39mdeepseek, model_name\u001b[38;5;241m=\u001b[39mdeepseek_name, dataset\u001b[38;5;241m=\u001b[39mhet_punDataset, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, examples\u001b[38;5;241m=\u001b[39mhet_examples, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[94], line 131\u001b[0m, in \u001b[0;36mcall_llm_to_generate\u001b[0;34m(model, dataset, model_name, method, examples, save, path_gen, batch_size)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_human_text[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepseek\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m--> 131\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepseek-chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m#decode response JSON\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     output \u001b[38;5;241m=\u001b[39m (json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent))[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[0;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 922\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generation method 2\n",
    "call_llm_to_generate(model=deepseek, model_name=deepseek_name, dataset=hom_punDataset, method=2, examples=hom_examples, batch_size=10, save=True)\n",
    "call_llm_to_generate(model=deepseek, model_name=deepseek_name, dataset=het_punDataset, method=2, examples=het_examples, batch_size=10, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2-vl-2b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2vl = 'qwen2-vl-2b-instruct'\n",
    "qwen2vl_name = 'qwen2-vl-2b-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/810 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 220, 0:\n",
      "human text: Doctor , doctor , I keep thinking I ' m a deck of cards . - I ' ll deal with you later . Next !\n",
      "LLM output: The doctor kept thinking 'I'm dealing with you later.'\n",
      "case 220, 1:\n",
      "human text: The ice at the rink has many ruts . I think the maintenance crew is slipping up .\n",
      "LLM output: The maintenance crew slipped up on the slippery ice.\n",
      "case 220, 2:\n",
      "human text: Two companies that manufactured rulers decided to align .\n",
      "LLM output: Companies have aligned themselves with new manufacturing methods and decided to align with the latest trends.\n",
      "case 220, 3:\n",
      "human text: Early nuclear experimenters discovered an element of surprise .\n",
      "LLM output: Nuclear experimenters are looking for new elements.\n",
      "case 220, 4:\n",
      "human text: ' ' I ' ve run out of wool , ' ' said Tom , knitting his brow .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 69)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 220, 5:\n",
      "human text: To write with a broken pencil is pointless .\n",
      "LLM output: This pencil was pointless.\n",
      "case 220, 6:\n",
      "human text: If you wear a blindfold at the shooting range , you won ' t know what you ' re missing .\n",
      "LLM output: I missed the shot on my first shot at the shooting range.\n",
      "case 220, 7:\n",
      "human text: Waiter , there are pennies in my soup ! ' ' Well , sir , you said you ' d stop eating here if there wasn ' t some change in the food . ' ' *\n",
      "LLM output: I made a change in my eating habits, but the soup didn't foil.\n",
      "case 220, 8:\n",
      "human text: Luggage salespeople have to make a good case for you to buy .\n",
      "LLM output: The salespeople were all over the place with their luggage.\n",
      "case 220, 9:\n",
      "human text: After Junior swallowed the watch he had to wait to pass the time .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 221/810 [00:12<00:32, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I watched a man swallow his time and pass it back.\n",
      "case 230, 0:\n",
      "human text: Nobel got a big bang out of it .\n",
      "LLM output: The Nobel had just given one last bang to the world.\n",
      "case 230, 1:\n",
      "human text: Doctor , Doctor , what would you take for this cold ? - Make me an offer . Next .\n",
      "LLM output: The doctor made me an offer for the cold.\n",
      "case 230, 2:\n",
      "human text: ' ' Waiter , there ' s a fly in my soup ! ' ' ' ' Force of habit , sir , the chef used to be a tailor .\n",
      "LLM output: The chef's tailors fly were flying again.\n",
      "case 230, 3:\n",
      "human text: Two pencils decided to have a race . The outcome was a draw .\n",
      "LLM output: Two pencils drew two races, but the outcome was still uncertain.\n",
      "case 230, 4:\n",
      "human text: Those working in tissue research and testing are always blowing it .\n",
      "LLM output: The test was blowing it.\n",
      "case 230, 5:\n",
      "human text: I crossed a cell phone with a skunk , and now the service stinks .\n",
      "LLM output: This stinky service has crossed my cell phone.\n",
      "case 230, 6:\n",
      "human text: Did you hear about the crime that happened in a parking garage ? It was wrong on so many levels .\n",
      "LLM output: Parking in the garage was a real challenge.\n",
      "case 230, 7:\n",
      "human text: He collects mouthwash bottles , and they ' re all in mint condition .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 67)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 230, 8:\n",
      "human text: One palm tree said to another ' let ' s have a date . '\n",
      "LLM output: The date was a sweet treat for everyone.\n",
      "case 230, 9:\n",
      "human text: For the office drunk : He generally found him loaded with work to do .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 231/810 [00:24<01:12,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I was loaded from the office.\n",
      "case 240, 0:\n",
      "human text: The golfer guessed that his ball landed 20 feet off the fairway . Of course , that was just a rough estimate .\n",
      "LLM output: The golfer hit his ball into the rough.\n",
      "case 240, 1:\n",
      "human text: A circus lion won ' t eat clowns because they taste funny .\n",
      "LLM output: The lion in the clowns' circus was funny.\n",
      "case 240, 2:\n",
      "human text: Two referees went head to head because they had a score to settle .\n",
      "LLM output: The referee's decision was score.\n",
      "case 240, 3:\n",
      "human text: A pop singer bought a new house for a song .\n",
      "LLM output: I bought a house and sold it for a song.\n",
      "case 240, 4:\n",
      "human text: The owner of the hair salon had to make cuts on his staff .\n",
      "LLM output: The owner of the hair salon made a cut on one of his staff's hair.\n",
      "case 240, 5:\n",
      "human text: Business at the candle factory tapered off after the holidays .\n",
      "LLM output: The business was tapered off.\n",
      "case 240, 6:\n",
      "human text: OLD GOLFERS never die , they just lose their drive .\n",
      "LLM output: Old golfers can drive their passion for the sport.\n",
      "case 240, 7:\n",
      "human text: When it was lumpy he had a beef with his gravy .\n",
      "LLM output: The lumpy pieces of beef in the gravy were a bit too much.\n",
      "case 240, 8:\n",
      "human text: Pencil sharpeners have a tough life - they live off tips .\n",
      "LLM output: A pencil sharpener lived in the rough of tips.\n",
      "case 240, 9:\n",
      "human text: Two florists got married . It was an arranged marriage .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 241/810 [00:34<01:52,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: A florist had arranged the flowers, but the wedding had gone off without a hitch.\n",
      "case 250, 0:\n",
      "human text: When the plums dry on your tree , it ' s time to prune .\n",
      "LLM output: I pruned a few plums to make sure they didn't get overgrown.\n",
      "case 250, 1:\n",
      "human text: Cousteau was submerged in his work .\n",
      "LLM output: Cousteau's submarine was submerged and worked very well.\n",
      "case 250, 2:\n",
      "human text: Five brothers wanted to buy a horse , so they all had to pony up .\n",
      "LLM output: The brothers had to pony up for the horse.\n",
      "case 250, 3:\n",
      "human text: Sports are refereed by people of many stripes .\n",
      "LLM output: The referee refereed the game and there were many stripes on the ball.\n",
      "case 250, 4:\n",
      "human text: OLD PILOTS never die they just go to a higher plane .\n",
      "LLM output: The pilots of the future are going to the higher plane.\n",
      "case 250, 5:\n",
      "human text: If you get sick at the airport it could be a terminal illness .\n",
      "LLM output: When my terminal illness was at its worst, I spent most of my days waiting for the flight to take off.\n",
      "case 250, 6:\n",
      "human text: Be true to your teeth , or they will be false to you .\n",
      "LLM output: The tooth fairy told me she was a false.\n",
      "case 250, 7:\n",
      "human text: The Easter story is not a dead issue .\n",
      "LLM output: The Easter story was dead to me.\n",
      "case 250, 8:\n",
      "human text: Dont let your footprints in the sands of time be the mark of a heel\n",
      "LLM output: A person with a footprint on his heel was considered morally reprehensible.\n",
      "case 250, 9:\n",
      "human text: My new expensive vacuum cleaner really sucked .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 251/810 [00:45<02:41,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I was so bored that I had to be sucked into the cleaning machine.\n",
      "case 260, 0:\n",
      "human text: Doctor , Doctor , my hair is coming out . What can you give me to keep it in ? - A cigar box . Next .\n",
      "LLM output: The doctor kept her hair in a box.\n",
      "case 260, 1:\n",
      "human text: Scientists have created a flea from scratch .\n",
      "LLM output: Scientists scratched at the flea and continued to scratch.\n",
      "case 260, 2:\n",
      "human text: Two blackberries met . They were both in a jam .\n",
      "LLM output: Two blackberries both in a jam was jamming.\n",
      "case 260, 3:\n",
      "human text: If you sight a whale , it could be a fluke .\n",
      "LLM output: A whale fluked into our boat again.\n",
      "case 260, 4:\n",
      "human text: OLD FLORISTS never die , they just make alternative arrangements .\n",
      "LLM output: My FLORIST gave me an alternative arrangement.\n",
      "case 260, 5:\n",
      "human text: A person who would make a banking joke is of no account .\n",
      "LLM output: I'm a bit out of my 'no' account.\n",
      "case 260, 6:\n",
      "human text: He bought a plate with four corners so he could have a square meal .\n",
      "LLM output: The plate corners were too square for my taste.\n",
      "case 260, 7:\n",
      "human text: The plot to his story of the pond was quite shallow .\n",
      "LLM output: There was so much shallow water in the pond.\n",
      "case 260, 8:\n",
      "human text: My boyfriend and I started to date after he backed his car into mine . We met by accident .\n",
      "LLM output: I met my boyfriend on a blind date. I had no idea it would turn out so well.\n",
      "case 260, 9:\n",
      "human text: Why was the car embarrassed ? Because it had gas !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 261/810 [00:55<03:27,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The gas in the car made me embarassed.\n",
      "case 270, 0:\n",
      "human text: A boating accident between the yacht , Red Dawn , and the schooner , Blue Lagoon , left the survivors marooned .\n",
      "LLM output: A boater was marooned on a desert island without resources.\n",
      "case 270, 1:\n",
      "human text: A mechanic who was also a musician was good at tuning things .\n",
      "LLM output: The musician's tuning was perfect, but the mechanic's tuning was still a bit off.\n",
      "case 270, 2:\n",
      "human text: I ' ve struck oil ! Tom gushed .\n",
      "LLM output: The oil gushed forth in a sudden stream.\n",
      "case 270, 3:\n",
      "human text: Doctor , Doctor , you ' ve got to help me . I think I ' m a kleptomaniac . - Don ' t worry . I think there ' s something you can take for that . Next .\n",
      "LLM output: The doctor took a patient and the kleptomaniac took a new outfit.\n",
      "case 270, 4:\n",
      "human text: I watched a movie about a baby hen , it was a real chick flick .\n",
      "LLM output: I can't believe I'm watching this chick flick.\n",
      "case 270, 5:\n",
      "human text: Studying fungus is a way to mold young minds .\n",
      "LLM output: Young minds are like fungi growing in the dark.\n",
      "case 270, 6:\n",
      "human text: She was only a Fruit vender ' s daughter , but , oh , what a peach .\n",
      "LLM output: This peach looked so good that it had to be sampled at the fruit vendor's stall.\n",
      "case 270, 7:\n",
      "human text: The waiter was shocked when I asked for my salad to be served naked . I explained , no dressing please .\n",
      "LLM output: The salad was naked and had no dressing.\n",
      "case 270, 8:\n",
      "human text: Can honeybee abuse lead to a sting operation ?\n",
      "LLM output: The honey bee sting was a sting operation for abuse.\n",
      "case 270, 9:\n",
      "human text: OLD BLASTING TECHNICIANS never die , they just lose their spark .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 271/810 [01:05<04:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: Never die, but always be the last to leave.\n",
      "case 280, 0:\n",
      "human text: If you leave alphabet soup on the stove and go out , it could spell disaster .\n",
      "LLM output: The Alphabet Soup spelled on the stove could spell disaster.\n",
      "case 280, 1:\n",
      "human text: If you work in a forestry company you will probably have to log your time .\n",
      "LLM output: The forestry company was logging trees for its wood.\n",
      "case 280, 2:\n",
      "human text: OLD BUNGEE JUMPERS sometimes die but they can still bounce back\n",
      "LLM output: A bungee jumper had to bounce back after the jump.\n",
      "case 280, 3:\n",
      "human text: They built a tree house together but then had a falling out .\n",
      "LLM output: Together they fell out of their tree house.\n",
      "case 280, 4:\n",
      "human text: ' ' Consult an investment broker , ' ' was Tom ' s stock answer .\n",
      "LLM output: The broker was stock and ready to trade.\n",
      "case 280, 5:\n",
      "human text: A basketball player couldn ' t control his saliva but he could sure dribble .\n",
      "LLM output: The basketball was dribbled by one player in a game.\n",
      "case 280, 6:\n",
      "human text: Some people really enjoy blowing air out of their lungs - I ' m not a fan myself .\n",
      "LLM output: Some people enjoy blowing air and don't even know it.\n",
      "case 280, 7:\n",
      "human text: The weatherman who forecasted snow in July was a bit of a flake .\n",
      "LLM output: The weatherman said that the July flake was going to be a bit cold.\n",
      "case 280, 8:\n",
      "human text: If you go for a job interview at a rubber stamp company try to make a good impression .\n",
      "LLM output: The rubber stamp made a good impression on their company.\n",
      "case 280, 9:\n",
      "human text: OLD PRINCIPALS never die they just lose their faculties .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 281/810 [01:15<05:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The principals never die but they have lost their faculties.\n",
      "case 290, 0:\n",
      "human text: Convicts are committed people .\n",
      "LLM output: The convict was committed for his crime.\n",
      "case 290, 1:\n",
      "human text: The race dogs got a bad case of the fleas - they had to be scratched .\n",
      "LLM output: Race dogs scratched to the bone.\n",
      "case 290, 2:\n",
      "human text: A woman who became queen considered it her crowning achievement .\n",
      "LLM output: The woman became queen and was crowned with her achievements.\n",
      "case 290, 3:\n",
      "human text: We ' ll never run out of math teachers because they always multiply .\n",
      "LLM output: The math teacher said to the student 'Multiply run out.'\n",
      "case 290, 4:\n",
      "human text: Even though Catholics in space are weightless , do they have mass ?\n",
      "LLM output: The space was weightless, but the Catholics still celebrated it.\n",
      "case 290, 5:\n",
      "human text: OLD PILOTS never die , they just buzz off .\n",
      "LLM output: PILOTS, die, buzz off.\n",
      "case 290, 6:\n",
      "human text: A tailor sometimes decides to suit himself .\n",
      "LLM output: The tailor said to himself 'suit yourself.'\n",
      "case 290, 7:\n",
      "human text: OLD TREE SURGEONS never die , they are just uprooted .\n",
      "LLM output: The surgeon uprooted the tree.\n",
      "case 290, 8:\n",
      "human text: A new type of broom came out , it is sweeping the nation .\n",
      "LLM output: Sweeping the nation was the biggest win of all.\n",
      "case 290, 9:\n",
      "human text: The pope , on his 2008 tour in the United States , skipped Mass .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 291/810 [01:24<05:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The pope skipped Mass in his tour.\n",
      "case 300, 0:\n",
      "human text: She was only a Globetrotter ' s daughter , but she manages to get around .\n",
      "LLM output: A globetrotter gets around a lot.\n",
      "case 300, 1:\n",
      "human text: To become an electrician you have to pass a battery of tests .\n",
      "LLM output: The electrician passed the battery of tests.\n",
      "case 300, 2:\n",
      "human text: A student limped into class with a lame excuse .\n",
      "LLM output: The driver who limped into the service station was using a lame excuse.\n",
      "case 300, 3:\n",
      "human text: If you burn the candle on both ends , youre not as bright as you think .\n",
      "LLM output: The candle was burning on both ends.\n",
      "case 300, 4:\n",
      "human text: OLD MUSICIANS never die they just get played out .\n",
      "LLM output: The musician's band played out, and they all died.\n",
      "case 300, 5:\n",
      "human text: What it boils down to is this : eggs taste good .\n",
      "LLM output: Eggs boiled up to the boil.\n",
      "case 300, 6:\n",
      "human text: Weather forecasters have to have lots of degrees .\n",
      "LLM output: The forecasters were giving us lots and lots of degrees.\n",
      "case 300, 7:\n",
      "human text: Salespeople selling security equipment like to see people get alarmed .\n",
      "LLM output: The security equipment was alarmed when the salespeople tried to sell me something I didn't need.\n",
      "case 300, 8:\n",
      "human text: OLD SANITATION MEN never die , they just waste away\n",
      "LLM output: The sanitation men died from waste.\n",
      "case 300, 9:\n",
      "human text: The fire chief was always asked burning questions .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 301/810 [01:34<06:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The fire chief was burning questions.\n",
      "case 310, 0:\n",
      "human text: OLD GEOGRAPHERS never die , they just become legends .\n",
      "LLM output: The geographer died of a heart attack and left his legends behind.\n",
      "case 310, 1:\n",
      "human text: The place that made rubber balls almost went bankrupt , but they bounced back .\n",
      "LLM output: The place where the rubber balls were made was almost bankrupt.\n",
      "case 310, 2:\n",
      "human text: OLD MOONSHINERS never die , they just keep still .\n",
      "LLM output: The moonshiners still die but they've still got their stills.\n",
      "case 310, 3:\n",
      "human text: If you have to pay to go to the river , we ' d better stop at the bank .\n",
      "LLM output: I'm paying my bill and the bank is right next to it.\n",
      "case 310, 4:\n",
      "human text: Humpty Dumpty had a great fall - and a pretty good spring and summer , too .\n",
      "LLM output: Humpty Dumpty sat on his great fall and was very sad.\n",
      "case 310, 5:\n",
      "human text: The man who worked in the gum factory fell in a vat of bubblegum . His boss had to chew him out .\n",
      "LLM output: The boss chewed him out for falling in a vat of bubblegum.\n",
      "case 310, 6:\n",
      "human text: Are giraffes good pets or are they too high maintenance ?\n",
      "LLM output: A giraffe is not only a tall animal but also a good pet.\n",
      "case 310, 7:\n",
      "human text: Soon after he joined the band , the guitarist was instrumental .\n",
      "LLM output: The guitarist's instrument was a crucial part of the band.\n",
      "case 310, 8:\n",
      "human text: Becoming a yoga instructor offers the possibilities of a unique teaching position .\n",
      "LLM output: The yoga instructor taught a unique position.\n",
      "case 310, 9:\n",
      "human text: His business plan to manufacture scissors just didn ' t cut it .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 311/810 [01:45<06:42,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I cut my business plan and started cutting it.\n",
      "case 320, 0:\n",
      "human text: Did you hear about the guy whose whole left side was cut off ? He ' s all right now .\n",
      "LLM output: That's the guy who cut off his right side now.\n",
      "case 320, 1:\n",
      "human text: Always trust a glue salesman . They tend to stick to their word .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 82)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 320, 2:\n",
      "human text: Two airline pilots in a stand - up comedy did a takeoff .\n",
      "LLM output: An airline pilot stood up on the runway and took off.\n",
      "case 320, 3:\n",
      "human text: Acrobats are always doing good turns .\n",
      "LLM output: The acrobats were performing a good turn.\n",
      "case 320, 4:\n",
      "human text: ' ' I invested in a hi - tech startup , ' ' Tom ventured .\n",
      "LLM output: He invested in hi - tech startups and ventured to succeed.\n",
      "case 320, 5:\n",
      "human text: Gardeners like to spring into action .\n",
      "LLM output: The gardener was springing ahead with his tools.\n",
      "case 320, 6:\n",
      "human text: OLD PAINTERS never die they just get plastered .\n",
      "LLM output: The PAINTER who painted the die was so plastered that he had to be brought back.\n",
      "case 320, 7:\n",
      "human text: Archimedes was buoyant at the thought .\n",
      "LLM output: Archimedes was buoyant with his latest discovery.\n",
      "case 320, 8:\n",
      "human text: Those who like sport fishing can really get hooked .\n",
      "LLM output: The fisherman hooked a big one.\n",
      "case 320, 9:\n",
      "human text: Derringer had one shot at fame .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 321/810 [01:56<07:17,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The Derringer shot at fame.\n",
      "case 330, 0:\n",
      "human text: The guy who sold his carnival got a Fair deal .\n",
      "LLM output: The guy in the carnival sold a deal that was not fair.\n",
      "case 330, 1:\n",
      "human text: I usually take steps to avoid elevators .\n",
      "LLM output: Avoiding the elevators and taking the steps.\n",
      "case 330, 2:\n",
      "human text: Why don ' t people like to talk to garbage men ? They mostly talk trash .\n",
      "LLM output: Why don' t people talk garbage men?\n",
      "case 330, 3:\n",
      "human text: When the human cannonball was late for work he got fired .\n",
      "LLM output: The human cannonball was fired late.\n",
      "case 330, 4:\n",
      "human text: In equations with square numbers I can never find the root of the problem .\n",
      "LLM output: The equation had to be solved by multiplying the numbers and looking for the root.\n",
      "case 330, 5:\n",
      "human text: He was selling palm trees , but people thought it was a shady deal .\n",
      "LLM output: The shady deal sold some of the palm trees.\n",
      "case 330, 6:\n",
      "human text: There was a sale at the fish market today . I went to see what was the catch .\n",
      "LLM output: The fish market was full of what we catch.\n",
      "case 330, 7:\n",
      "human text: ' ' Angel dust ? Me ? Never touch it ! ' ' Tom snorted .\n",
      "LLM output: An angel dust snorted through my nose.\n",
      "case 330, 8:\n",
      "human text: Old bakers never die , they just keep making lots of dough .\n",
      "LLM output: The baker was making dough on the kitchen counter.\n",
      "case 330, 9:\n",
      "human text: You often hear of a good wine through the grapevine .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 331/810 [02:06<07:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The grapevine spread the news of my job change.\n",
      "case 340, 0:\n",
      "human text: When the tornado went through town it was quite a blow .\n",
      "LLM output: The town was hit by a quite a blow.\n",
      "case 340, 1:\n",
      "human text: I couldn ' t stand to be without my legs .\n",
      "LLM output: I couldn't stand without my legs.\n",
      "case 340, 2:\n",
      "human text: The two inventors of the radio were on the same wavelength .\n",
      "LLM output: Radio inventors had a wavelength to share.\n",
      "case 340, 3:\n",
      "human text: OLD HOCKEY PLAYERS never die , they just achieve their final goal .\n",
      "LLM output: The HOCKEY players were dying to reach the goal.\n",
      "case 340, 4:\n",
      "human text: The guitarist passed out on stage , he must have rocked himself to sleep .\n",
      "LLM output: The guitarist passed out after rocking all night long.\n",
      "case 340, 5:\n",
      "human text: Decimals have a point .\n",
      "LLM output: He had his point about the decimals.\n",
      "case 340, 6:\n",
      "human text: For the orthodontist visit , the boy had to brace himself .\n",
      "LLM output: The braces had been placed to brace myself.\n",
      "case 340, 7:\n",
      "human text: OLD SOCCER PLAYERS never die , they just achieve their final goal .\n",
      "LLM output: The soccer players celebrated their goal with a grand celebration.\n",
      "case 340, 8:\n",
      "human text: Police can do a search if it ' s Warranted .\n",
      "LLM output: The police searched the warrant.\n",
      "case 340, 9:\n",
      "human text: The correct formula for concrete is worthwhile to cement in your mind .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 341/810 [02:16<07:20,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The formula was the cement for their success.\n",
      "case 350, 0:\n",
      "human text: The inventor of the fahrenheit scale solved the problem by degrees .\n",
      "LLM output: A fahrenheit was reading degrees.\n",
      "case 350, 1:\n",
      "human text: My comb is invaluable - I can ' t part with it .\n",
      "LLM output: The valuable comb was part of my hair.\n",
      "case 350, 2:\n",
      "human text: If you don ' t know how to choose music ask a guitarist - they know how to pick .\n",
      "LLM output: I picked the right music and asked for a guitar pick.\n",
      "case 350, 3:\n",
      "human text: A city worker who campaigned for new sewer pipes finally had to go underground .\n",
      "LLM output: A city worker campaigned for underground access to the sewers.\n",
      "case 350, 4:\n",
      "human text: OLD SOCCER PLAYERS never die , they just go on dribbling .\n",
      "LLM output: The soccer player did not have any die to dribble.\n",
      "case 350, 5:\n",
      "human text: Marconi was not wired up about going .\n",
      "LLM output: Marconi's wireless communication system was wired to the radio station.\n",
      "case 350, 6:\n",
      "human text: OLD PROFESSORS never die , they just lose their class .\n",
      "Error parsing response: Unterminated string starting at: line 1 column 14 (char 13)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 350, 7:\n",
      "human text: Pick your friends , but not to pieces\n",
      "LLM output: My friends picked my pocket.\n",
      "case 350, 8:\n",
      "human text: I bought a metronome for 20 bucks . You can ' t beat that price .\n",
      "LLM output: At the 20 bucks price, it was a bit of a beat.\n",
      "case 350, 9:\n",
      "human text: I can ' t really see myself without eyes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 351/810 [02:26<07:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I don't see myself without eyes.\n",
      "case 360, 0:\n",
      "human text: The forecaster was away because he was under the weather .\n",
      "LLM output: The forecasters were under the weather again.\n",
      "case 360, 1:\n",
      "human text: The weigh - in at the Sumo wrestling tournament was a large scale effort .\n",
      "LLM output: The sumo weighs in at a large-scale effort.\n",
      "case 360, 2:\n",
      "human text: An elephant ' s opinion carries a lot of weight .\n",
      "LLM output: The elephant's opinion weighed heavily in the matter.\n",
      "case 360, 3:\n",
      "human text: Officer Jones takes his yearly bath every June . He is a characteristic example of a dirty cop .\n",
      "LLM output: An officer was soiled and a dirty year had been.\n",
      "case 360, 4:\n",
      "human text: OLD GUNS never die they just get loaded .\n",
      "LLM output: The old guns were still loaded and the shot was getting loaded.\n",
      "case 360, 5:\n",
      "human text: He put bug spray on his watch to get rid of the ticks .\n",
      "LLM output: I thought I'd take a little break and watch some bugs get rid of themselves.\n",
      "case 360, 6:\n",
      "human text: When you ' re wearing a watch on an airplane , time flies .\n",
      "LLM output: The watch said 'time flies'.\n",
      "case 360, 7:\n",
      "human text: Bowling Alley : Please be quiet . We need to hear a pin drop .\n",
      "LLM output: The bowling pin quietly pin'd down the quiet drop.\n",
      "case 360, 8:\n",
      "human text: Employers like their mechanics to be geared up .\n",
      "LLM output: The employers geared their mechanics to meet the demands.\n",
      "case 360, 9:\n",
      "human text: Lifes a ledger , are we giving a good accounting of ourselves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 361/810 [02:36<07:10,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: Lifes ledger was showing our own accounting.\n",
      "case 370, 0:\n",
      "human text: If you give some managers an inch they think they ' re a ruler .\n",
      "LLM output: Managers gave their employees rulers to think about their performance.\n",
      "case 370, 1:\n",
      "human text: The Transformer always had a lot of quarters with him . He was a big fan of change .\n",
      "LLM output: The transformer was changing its quarters.\n",
      "case 370, 2:\n",
      "human text: Whenever the nurses have a bad day they just keep needling people .\n",
      "LLM output: The nurses were needling people all day long.\n",
      "case 370, 3:\n",
      "human text: His day job was astronomy but at night time he was moonlighting .\n",
      "LLM output: I work as a night shift astronomer during my day job.\n",
      "case 370, 4:\n",
      "human text: I can ' t recall the last time I did any running , but I ' ve been jogging my memory .\n",
      "LLM output: I can't recall the last time I jogged.\n",
      "case 370, 5:\n",
      "human text: OLD SCULPTORS never die they just lose their marbles .\n",
      "LLM output: The sculptors lost their marbles.\n",
      "case 370, 6:\n",
      "human text: At seven foot six he was a great basketball player and everyone looked up to him .\n",
      "LLM output: I looked up at the basketball court and felt admiration for its size.\n",
      "case 370, 7:\n",
      "human text: OLD CASHIERS never die they just check out .\n",
      "LLM output: The cashier said the check was out.\n",
      "case 370, 8:\n",
      "human text: A church welcomed all denominations but preferred tens and twenties .\n",
      "LLM output: The church welcomed all denominations and preferred tens.\n",
      "case 370, 9:\n",
      "human text: OLD WRITERS never die , they just get erased .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 371/810 [02:45<06:56,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The writer's words were erased to death.\n",
      "case 380, 0:\n",
      "human text: The All - Pro wide receiver ' s wedding was a little bit shaky , but his reception was excellent .\n",
      "LLM output: The wide receiver caught the reception at the wedding.\n",
      "case 380, 1:\n",
      "human text: She was only a Real estate agent ' ' s daughter , but she gave a lot away .\n",
      "LLM output: Real estate agent 's gave a lot of land.\n",
      "case 380, 2:\n",
      "human text: Sure I can climb cliffs ! Tom bluffed .\n",
      "LLM output: The cliffs bluffed the brave.\n",
      "case 380, 3:\n",
      "human text: He was trying to sell me new windows , but his motivations were transparent .\n",
      "LLM output: The window was transparent to the motives behind the sales.\n",
      "case 380, 4:\n",
      "human text: It ' s OK to watch an elephant bathe as they usually have their trunks on .\n",
      "LLM output: An elephant has its trunks on.\n",
      "case 380, 5:\n",
      "human text: A small boy went to the counter to pay for his lunch but he was a little short .\n",
      "LLM output: The small boy was counter-paid for his goods.\n",
      "case 380, 6:\n",
      "human text: Those who want to paint polka - dots have to find a good spot .\n",
      "LLM output: The painter's polka dots were the stars of the show.\n",
      "case 380, 7:\n",
      "human text: If a clock had legs , time would run out .\n",
      "LLM output: Time is running out for me.\n",
      "case 380, 8:\n",
      "human text: The teacher asked a question and the students were all up in arms .\n",
      "LLM output: The teacher was up in arms over the question.\n",
      "case 380, 9:\n",
      "human text: Why are all businessmen fat ? Must be all the inflation .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 381/810 [02:54<06:42,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The businessmen must be feeling the inflation.\n",
      "case 390, 0:\n",
      "human text: He realized he ' d made the major leagues when it finally hit him .\n",
      "LLM output: A player was hit by a pitch and left the game.\n",
      "case 390, 1:\n",
      "human text: My new theory on inertia doesn ' t seem to be gaining momentum .\n",
      "LLM output: A theory was gaining momentum.\n",
      "case 390, 2:\n",
      "human text: I know a rancher who has 100 head of cattle , but he thought there were only 99 until he rounded them up .\n",
      "LLM output: The rancher thought only of rounding them up.\n",
      "case 390, 3:\n",
      "human text: A locksmith has to have a good Combination of skills .\n",
      "LLM output: The locksmith was able to combine his skills to solve the puzzle.\n",
      "case 390, 4:\n",
      "human text: Leonardo Da Vinci could use a paint brush to make a stroke of genius .\n",
      "LLM output: The genius of Da Vinci had painted his stroke on the wall.\n",
      "case 390, 5:\n",
      "human text: OLD ACTUARIES never die they just get broken down by age and sex .\n",
      "LLM output: An actuary died from the effects of being broken down by age and sex.\n",
      "case 390, 6:\n",
      "human text: Joe refused to eat sushi because it looks fishy .\n",
      "LLM output: Joe refused to eat sushi and it looked fishy.\n",
      "case 390, 7:\n",
      "human text: Did you hear about the tire dealer that had a blowout sale ?\n",
      "LLM output: A tire had blown out and the shop was having a blowout sale.\n",
      "case 390, 8:\n",
      "human text: ' ' This wind is awful , ' ' blustered Tom .\n",
      "LLM output: The president blustered and showed off.\n",
      "case 390, 9:\n",
      "human text: This is where I keep my arrows , said Tom , quivering .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 391/810 [03:04<06:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The arrows were quivering in the breeze.\n",
      "case 400, 0:\n",
      "human text: So , how ' s the flower business going ? Oh , it ' s blossoming quite nicely .\n",
      "LLM output: The business is blossoming.\n",
      "case 400, 1:\n",
      "human text: Building a cul - de - sac would be a bit of a dead - end job .\n",
      "LLM output: The cul-de-sac at the end of my driveway was a dead end to me.\n",
      "case 400, 2:\n",
      "human text: Swimming instructors are always getting immersed in their work .\n",
      "LLM output: A swimming instructor immersed himself in the water and worked tirelessly.\n",
      "case 400, 3:\n",
      "human text: A dry cleaners had a dozen suits in court .\n",
      "LLM output: The dry cleaner couldn't find a suit that fit me.\n",
      "case 400, 4:\n",
      "human text: My student was late for class , claiming he was in the washroom . I think he was stalling .\n",
      "LLM output: The student claimed that he was in the washroom and might as well be in the stalling.\n",
      "case 400, 5:\n",
      "human text: We should make a beer commercial . It sounds simply intoxicating .\n",
      "LLM output: Beer commercials make us all sound intoxicating.\n",
      "case 400, 6:\n",
      "human text: They said he drank 2 bottles of whisky a day , but it wasn ' t true . He had to scotch those rumours right away .\n",
      "LLM output: A scotch bottle had become the center of a scotch rumor.\n",
      "case 400, 7:\n",
      "human text: She was only a Gardener ' s daughter , but she knows all the rakes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 400/810 [03:12<03:17,  2.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generation method 2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcall_llm_to_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqwen2vl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqwen2vl_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_punDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m call_llm_to_generate(model\u001b[38;5;241m=\u001b[39mqwen2vl, model_name\u001b[38;5;241m=\u001b[39mqwen2vl_name, dataset\u001b[38;5;241m=\u001b[39mhet_punDataset, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, examples\u001b[38;5;241m=\u001b[39mhet_examples, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[102], line 156\u001b[0m, in \u001b[0;36mcall_llm_to_generate\u001b[0;34m(model, dataset, model_name, method, examples, save, path_gen, batch_size)\u001b[0m\n\u001b[1;32m    145\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    146\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m }\n\u001b[0;32m--> 156\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generation method 2\n",
    "call_llm_to_generate(model=qwen2vl, model_name=qwen2vl_name, dataset=hom_punDataset, method=2, examples=hom_examples, batch_size=10, save=True)\n",
    "call_llm_to_generate(model=qwen2vl, model_name=qwen2vl_name, dataset=het_punDataset, method=2, examples=het_examples, batch_size=10, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qwen2-vl-2b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen2vl = 'qwen2-vl-2b-instruct'\n",
    "qwen2vl_name = 'qwen2-vl-2b-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/810 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 220, 0:\n",
      "human text: Doctor , doctor , I keep thinking I ' m a deck of cards . - I ' ll deal with you later . Next !\n",
      "LLM output: The doctor kept thinking 'I'm dealing with you later.'\n",
      "case 220, 1:\n",
      "human text: The ice at the rink has many ruts . I think the maintenance crew is slipping up .\n",
      "LLM output: The maintenance crew slipped up on the slippery ice.\n",
      "case 220, 2:\n",
      "human text: Two companies that manufactured rulers decided to align .\n",
      "LLM output: Companies have aligned themselves with new manufacturing methods and decided to align with the latest trends.\n",
      "case 220, 3:\n",
      "human text: Early nuclear experimenters discovered an element of surprise .\n",
      "LLM output: Nuclear experimenters are looking for new elements.\n",
      "case 220, 4:\n",
      "human text: ' ' I ' ve run out of wool , ' ' said Tom , knitting his brow .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 69)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 220, 5:\n",
      "human text: To write with a broken pencil is pointless .\n",
      "LLM output: This pencil was pointless.\n",
      "case 220, 6:\n",
      "human text: If you wear a blindfold at the shooting range , you won ' t know what you ' re missing .\n",
      "LLM output: I missed the shot on my first shot at the shooting range.\n",
      "case 220, 7:\n",
      "human text: Waiter , there are pennies in my soup ! ' ' Well , sir , you said you ' d stop eating here if there wasn ' t some change in the food . ' ' *\n",
      "LLM output: I made a change in my eating habits, but the soup didn't foil.\n",
      "case 220, 8:\n",
      "human text: Luggage salespeople have to make a good case for you to buy .\n",
      "LLM output: The salespeople were all over the place with their luggage.\n",
      "case 220, 9:\n",
      "human text: After Junior swallowed the watch he had to wait to pass the time .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 221/810 [00:12<00:32, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I watched a man swallow his time and pass it back.\n",
      "case 230, 0:\n",
      "human text: Nobel got a big bang out of it .\n",
      "LLM output: The Nobel had just given one last bang to the world.\n",
      "case 230, 1:\n",
      "human text: Doctor , Doctor , what would you take for this cold ? - Make me an offer . Next .\n",
      "LLM output: The doctor made me an offer for the cold.\n",
      "case 230, 2:\n",
      "human text: ' ' Waiter , there ' s a fly in my soup ! ' ' ' ' Force of habit , sir , the chef used to be a tailor .\n",
      "LLM output: The chef's tailors fly were flying again.\n",
      "case 230, 3:\n",
      "human text: Two pencils decided to have a race . The outcome was a draw .\n",
      "LLM output: Two pencils drew two races, but the outcome was still uncertain.\n",
      "case 230, 4:\n",
      "human text: Those working in tissue research and testing are always blowing it .\n",
      "LLM output: The test was blowing it.\n",
      "case 230, 5:\n",
      "human text: I crossed a cell phone with a skunk , and now the service stinks .\n",
      "LLM output: This stinky service has crossed my cell phone.\n",
      "case 230, 6:\n",
      "human text: Did you hear about the crime that happened in a parking garage ? It was wrong on so many levels .\n",
      "LLM output: Parking in the garage was a real challenge.\n",
      "case 230, 7:\n",
      "human text: He collects mouthwash bottles , and they ' re all in mint condition .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 67)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 230, 8:\n",
      "human text: One palm tree said to another ' let ' s have a date . '\n",
      "LLM output: The date was a sweet treat for everyone.\n",
      "case 230, 9:\n",
      "human text: For the office drunk : He generally found him loaded with work to do .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 231/810 [00:24<01:12,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I was loaded from the office.\n",
      "case 240, 0:\n",
      "human text: The golfer guessed that his ball landed 20 feet off the fairway . Of course , that was just a rough estimate .\n",
      "LLM output: The golfer hit his ball into the rough.\n",
      "case 240, 1:\n",
      "human text: A circus lion won ' t eat clowns because they taste funny .\n",
      "LLM output: The lion in the clowns' circus was funny.\n",
      "case 240, 2:\n",
      "human text: Two referees went head to head because they had a score to settle .\n",
      "LLM output: The referee's decision was score.\n",
      "case 240, 3:\n",
      "human text: A pop singer bought a new house for a song .\n",
      "LLM output: I bought a house and sold it for a song.\n",
      "case 240, 4:\n",
      "human text: The owner of the hair salon had to make cuts on his staff .\n",
      "LLM output: The owner of the hair salon made a cut on one of his staff's hair.\n",
      "case 240, 5:\n",
      "human text: Business at the candle factory tapered off after the holidays .\n",
      "LLM output: The business was tapered off.\n",
      "case 240, 6:\n",
      "human text: OLD GOLFERS never die , they just lose their drive .\n",
      "LLM output: Old golfers can drive their passion for the sport.\n",
      "case 240, 7:\n",
      "human text: When it was lumpy he had a beef with his gravy .\n",
      "LLM output: The lumpy pieces of beef in the gravy were a bit too much.\n",
      "case 240, 8:\n",
      "human text: Pencil sharpeners have a tough life - they live off tips .\n",
      "LLM output: A pencil sharpener lived in the rough of tips.\n",
      "case 240, 9:\n",
      "human text: Two florists got married . It was an arranged marriage .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 241/810 [00:34<01:52,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: A florist had arranged the flowers, but the wedding had gone off without a hitch.\n",
      "case 250, 0:\n",
      "human text: When the plums dry on your tree , it ' s time to prune .\n",
      "LLM output: I pruned a few plums to make sure they didn't get overgrown.\n",
      "case 250, 1:\n",
      "human text: Cousteau was submerged in his work .\n",
      "LLM output: Cousteau's submarine was submerged and worked very well.\n",
      "case 250, 2:\n",
      "human text: Five brothers wanted to buy a horse , so they all had to pony up .\n",
      "LLM output: The brothers had to pony up for the horse.\n",
      "case 250, 3:\n",
      "human text: Sports are refereed by people of many stripes .\n",
      "LLM output: The referee refereed the game and there were many stripes on the ball.\n",
      "case 250, 4:\n",
      "human text: OLD PILOTS never die they just go to a higher plane .\n",
      "LLM output: The pilots of the future are going to the higher plane.\n",
      "case 250, 5:\n",
      "human text: If you get sick at the airport it could be a terminal illness .\n",
      "LLM output: When my terminal illness was at its worst, I spent most of my days waiting for the flight to take off.\n",
      "case 250, 6:\n",
      "human text: Be true to your teeth , or they will be false to you .\n",
      "LLM output: The tooth fairy told me she was a false.\n",
      "case 250, 7:\n",
      "human text: The Easter story is not a dead issue .\n",
      "LLM output: The Easter story was dead to me.\n",
      "case 250, 8:\n",
      "human text: Dont let your footprints in the sands of time be the mark of a heel\n",
      "LLM output: A person with a footprint on his heel was considered morally reprehensible.\n",
      "case 250, 9:\n",
      "human text: My new expensive vacuum cleaner really sucked .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 251/810 [00:45<02:41,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I was so bored that I had to be sucked into the cleaning machine.\n",
      "case 260, 0:\n",
      "human text: Doctor , Doctor , my hair is coming out . What can you give me to keep it in ? - A cigar box . Next .\n",
      "LLM output: The doctor kept her hair in a box.\n",
      "case 260, 1:\n",
      "human text: Scientists have created a flea from scratch .\n",
      "LLM output: Scientists scratched at the flea and continued to scratch.\n",
      "case 260, 2:\n",
      "human text: Two blackberries met . They were both in a jam .\n",
      "LLM output: Two blackberries both in a jam was jamming.\n",
      "case 260, 3:\n",
      "human text: If you sight a whale , it could be a fluke .\n",
      "LLM output: A whale fluked into our boat again.\n",
      "case 260, 4:\n",
      "human text: OLD FLORISTS never die , they just make alternative arrangements .\n",
      "LLM output: My FLORIST gave me an alternative arrangement.\n",
      "case 260, 5:\n",
      "human text: A person who would make a banking joke is of no account .\n",
      "LLM output: I'm a bit out of my 'no' account.\n",
      "case 260, 6:\n",
      "human text: He bought a plate with four corners so he could have a square meal .\n",
      "LLM output: The plate corners were too square for my taste.\n",
      "case 260, 7:\n",
      "human text: The plot to his story of the pond was quite shallow .\n",
      "LLM output: There was so much shallow water in the pond.\n",
      "case 260, 8:\n",
      "human text: My boyfriend and I started to date after he backed his car into mine . We met by accident .\n",
      "LLM output: I met my boyfriend on a blind date. I had no idea it would turn out so well.\n",
      "case 260, 9:\n",
      "human text: Why was the car embarrassed ? Because it had gas !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 261/810 [00:55<03:27,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The gas in the car made me embarassed.\n",
      "case 270, 0:\n",
      "human text: A boating accident between the yacht , Red Dawn , and the schooner , Blue Lagoon , left the survivors marooned .\n",
      "LLM output: A boater was marooned on a desert island without resources.\n",
      "case 270, 1:\n",
      "human text: A mechanic who was also a musician was good at tuning things .\n",
      "LLM output: The musician's tuning was perfect, but the mechanic's tuning was still a bit off.\n",
      "case 270, 2:\n",
      "human text: I ' ve struck oil ! Tom gushed .\n",
      "LLM output: The oil gushed forth in a sudden stream.\n",
      "case 270, 3:\n",
      "human text: Doctor , Doctor , you ' ve got to help me . I think I ' m a kleptomaniac . - Don ' t worry . I think there ' s something you can take for that . Next .\n",
      "LLM output: The doctor took a patient and the kleptomaniac took a new outfit.\n",
      "case 270, 4:\n",
      "human text: I watched a movie about a baby hen , it was a real chick flick .\n",
      "LLM output: I can't believe I'm watching this chick flick.\n",
      "case 270, 5:\n",
      "human text: Studying fungus is a way to mold young minds .\n",
      "LLM output: Young minds are like fungi growing in the dark.\n",
      "case 270, 6:\n",
      "human text: She was only a Fruit vender ' s daughter , but , oh , what a peach .\n",
      "LLM output: This peach looked so good that it had to be sampled at the fruit vendor's stall.\n",
      "case 270, 7:\n",
      "human text: The waiter was shocked when I asked for my salad to be served naked . I explained , no dressing please .\n",
      "LLM output: The salad was naked and had no dressing.\n",
      "case 270, 8:\n",
      "human text: Can honeybee abuse lead to a sting operation ?\n",
      "LLM output: The honey bee sting was a sting operation for abuse.\n",
      "case 270, 9:\n",
      "human text: OLD BLASTING TECHNICIANS never die , they just lose their spark .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 271/810 [01:05<04:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: Never die, but always be the last to leave.\n",
      "case 280, 0:\n",
      "human text: If you leave alphabet soup on the stove and go out , it could spell disaster .\n",
      "LLM output: The Alphabet Soup spelled on the stove could spell disaster.\n",
      "case 280, 1:\n",
      "human text: If you work in a forestry company you will probably have to log your time .\n",
      "LLM output: The forestry company was logging trees for its wood.\n",
      "case 280, 2:\n",
      "human text: OLD BUNGEE JUMPERS sometimes die but they can still bounce back\n",
      "LLM output: A bungee jumper had to bounce back after the jump.\n",
      "case 280, 3:\n",
      "human text: They built a tree house together but then had a falling out .\n",
      "LLM output: Together they fell out of their tree house.\n",
      "case 280, 4:\n",
      "human text: ' ' Consult an investment broker , ' ' was Tom ' s stock answer .\n",
      "LLM output: The broker was stock and ready to trade.\n",
      "case 280, 5:\n",
      "human text: A basketball player couldn ' t control his saliva but he could sure dribble .\n",
      "LLM output: The basketball was dribbled by one player in a game.\n",
      "case 280, 6:\n",
      "human text: Some people really enjoy blowing air out of their lungs - I ' m not a fan myself .\n",
      "LLM output: Some people enjoy blowing air and don't even know it.\n",
      "case 280, 7:\n",
      "human text: The weatherman who forecasted snow in July was a bit of a flake .\n",
      "LLM output: The weatherman said that the July flake was going to be a bit cold.\n",
      "case 280, 8:\n",
      "human text: If you go for a job interview at a rubber stamp company try to make a good impression .\n",
      "LLM output: The rubber stamp made a good impression on their company.\n",
      "case 280, 9:\n",
      "human text: OLD PRINCIPALS never die they just lose their faculties .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 281/810 [01:15<05:02,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The principals never die but they have lost their faculties.\n",
      "case 290, 0:\n",
      "human text: Convicts are committed people .\n",
      "LLM output: The convict was committed for his crime.\n",
      "case 290, 1:\n",
      "human text: The race dogs got a bad case of the fleas - they had to be scratched .\n",
      "LLM output: Race dogs scratched to the bone.\n",
      "case 290, 2:\n",
      "human text: A woman who became queen considered it her crowning achievement .\n",
      "LLM output: The woman became queen and was crowned with her achievements.\n",
      "case 290, 3:\n",
      "human text: We ' ll never run out of math teachers because they always multiply .\n",
      "LLM output: The math teacher said to the student 'Multiply run out.'\n",
      "case 290, 4:\n",
      "human text: Even though Catholics in space are weightless , do they have mass ?\n",
      "LLM output: The space was weightless, but the Catholics still celebrated it.\n",
      "case 290, 5:\n",
      "human text: OLD PILOTS never die , they just buzz off .\n",
      "LLM output: PILOTS, die, buzz off.\n",
      "case 290, 6:\n",
      "human text: A tailor sometimes decides to suit himself .\n",
      "LLM output: The tailor said to himself 'suit yourself.'\n",
      "case 290, 7:\n",
      "human text: OLD TREE SURGEONS never die , they are just uprooted .\n",
      "LLM output: The surgeon uprooted the tree.\n",
      "case 290, 8:\n",
      "human text: A new type of broom came out , it is sweeping the nation .\n",
      "LLM output: Sweeping the nation was the biggest win of all.\n",
      "case 290, 9:\n",
      "human text: The pope , on his 2008 tour in the United States , skipped Mass .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 291/810 [01:24<05:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The pope skipped Mass in his tour.\n",
      "case 300, 0:\n",
      "human text: She was only a Globetrotter ' s daughter , but she manages to get around .\n",
      "LLM output: A globetrotter gets around a lot.\n",
      "case 300, 1:\n",
      "human text: To become an electrician you have to pass a battery of tests .\n",
      "LLM output: The electrician passed the battery of tests.\n",
      "case 300, 2:\n",
      "human text: A student limped into class with a lame excuse .\n",
      "LLM output: The driver who limped into the service station was using a lame excuse.\n",
      "case 300, 3:\n",
      "human text: If you burn the candle on both ends , youre not as bright as you think .\n",
      "LLM output: The candle was burning on both ends.\n",
      "case 300, 4:\n",
      "human text: OLD MUSICIANS never die they just get played out .\n",
      "LLM output: The musician's band played out, and they all died.\n",
      "case 300, 5:\n",
      "human text: What it boils down to is this : eggs taste good .\n",
      "LLM output: Eggs boiled up to the boil.\n",
      "case 300, 6:\n",
      "human text: Weather forecasters have to have lots of degrees .\n",
      "LLM output: The forecasters were giving us lots and lots of degrees.\n",
      "case 300, 7:\n",
      "human text: Salespeople selling security equipment like to see people get alarmed .\n",
      "LLM output: The security equipment was alarmed when the salespeople tried to sell me something I didn't need.\n",
      "case 300, 8:\n",
      "human text: OLD SANITATION MEN never die , they just waste away\n",
      "LLM output: The sanitation men died from waste.\n",
      "case 300, 9:\n",
      "human text: The fire chief was always asked burning questions .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 301/810 [01:34<06:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The fire chief was burning questions.\n",
      "case 310, 0:\n",
      "human text: OLD GEOGRAPHERS never die , they just become legends .\n",
      "LLM output: The geographer died of a heart attack and left his legends behind.\n",
      "case 310, 1:\n",
      "human text: The place that made rubber balls almost went bankrupt , but they bounced back .\n",
      "LLM output: The place where the rubber balls were made was almost bankrupt.\n",
      "case 310, 2:\n",
      "human text: OLD MOONSHINERS never die , they just keep still .\n",
      "LLM output: The moonshiners still die but they've still got their stills.\n",
      "case 310, 3:\n",
      "human text: If you have to pay to go to the river , we ' d better stop at the bank .\n",
      "LLM output: I'm paying my bill and the bank is right next to it.\n",
      "case 310, 4:\n",
      "human text: Humpty Dumpty had a great fall - and a pretty good spring and summer , too .\n",
      "LLM output: Humpty Dumpty sat on his great fall and was very sad.\n",
      "case 310, 5:\n",
      "human text: The man who worked in the gum factory fell in a vat of bubblegum . His boss had to chew him out .\n",
      "LLM output: The boss chewed him out for falling in a vat of bubblegum.\n",
      "case 310, 6:\n",
      "human text: Are giraffes good pets or are they too high maintenance ?\n",
      "LLM output: A giraffe is not only a tall animal but also a good pet.\n",
      "case 310, 7:\n",
      "human text: Soon after he joined the band , the guitarist was instrumental .\n",
      "LLM output: The guitarist's instrument was a crucial part of the band.\n",
      "case 310, 8:\n",
      "human text: Becoming a yoga instructor offers the possibilities of a unique teaching position .\n",
      "LLM output: The yoga instructor taught a unique position.\n",
      "case 310, 9:\n",
      "human text: His business plan to manufacture scissors just didn ' t cut it .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 311/810 [01:45<06:42,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I cut my business plan and started cutting it.\n",
      "case 320, 0:\n",
      "human text: Did you hear about the guy whose whole left side was cut off ? He ' s all right now .\n",
      "LLM output: That's the guy who cut off his right side now.\n",
      "case 320, 1:\n",
      "human text: Always trust a glue salesman . They tend to stick to their word .\n",
      "Error parsing response: Extra data: line 3 column 1 (char 82)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 320, 2:\n",
      "human text: Two airline pilots in a stand - up comedy did a takeoff .\n",
      "LLM output: An airline pilot stood up on the runway and took off.\n",
      "case 320, 3:\n",
      "human text: Acrobats are always doing good turns .\n",
      "LLM output: The acrobats were performing a good turn.\n",
      "case 320, 4:\n",
      "human text: ' ' I invested in a hi - tech startup , ' ' Tom ventured .\n",
      "LLM output: He invested in hi - tech startups and ventured to succeed.\n",
      "case 320, 5:\n",
      "human text: Gardeners like to spring into action .\n",
      "LLM output: The gardener was springing ahead with his tools.\n",
      "case 320, 6:\n",
      "human text: OLD PAINTERS never die they just get plastered .\n",
      "LLM output: The PAINTER who painted the die was so plastered that he had to be brought back.\n",
      "case 320, 7:\n",
      "human text: Archimedes was buoyant at the thought .\n",
      "LLM output: Archimedes was buoyant with his latest discovery.\n",
      "case 320, 8:\n",
      "human text: Those who like sport fishing can really get hooked .\n",
      "LLM output: The fisherman hooked a big one.\n",
      "case 320, 9:\n",
      "human text: Derringer had one shot at fame .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 321/810 [01:56<07:17,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The Derringer shot at fame.\n",
      "case 330, 0:\n",
      "human text: The guy who sold his carnival got a Fair deal .\n",
      "LLM output: The guy in the carnival sold a deal that was not fair.\n",
      "case 330, 1:\n",
      "human text: I usually take steps to avoid elevators .\n",
      "LLM output: Avoiding the elevators and taking the steps.\n",
      "case 330, 2:\n",
      "human text: Why don ' t people like to talk to garbage men ? They mostly talk trash .\n",
      "LLM output: Why don' t people talk garbage men?\n",
      "case 330, 3:\n",
      "human text: When the human cannonball was late for work he got fired .\n",
      "LLM output: The human cannonball was fired late.\n",
      "case 330, 4:\n",
      "human text: In equations with square numbers I can never find the root of the problem .\n",
      "LLM output: The equation had to be solved by multiplying the numbers and looking for the root.\n",
      "case 330, 5:\n",
      "human text: He was selling palm trees , but people thought it was a shady deal .\n",
      "LLM output: The shady deal sold some of the palm trees.\n",
      "case 330, 6:\n",
      "human text: There was a sale at the fish market today . I went to see what was the catch .\n",
      "LLM output: The fish market was full of what we catch.\n",
      "case 330, 7:\n",
      "human text: ' ' Angel dust ? Me ? Never touch it ! ' ' Tom snorted .\n",
      "LLM output: An angel dust snorted through my nose.\n",
      "case 330, 8:\n",
      "human text: Old bakers never die , they just keep making lots of dough .\n",
      "LLM output: The baker was making dough on the kitchen counter.\n",
      "case 330, 9:\n",
      "human text: You often hear of a good wine through the grapevine .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 331/810 [02:06<07:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The grapevine spread the news of my job change.\n",
      "case 340, 0:\n",
      "human text: When the tornado went through town it was quite a blow .\n",
      "LLM output: The town was hit by a quite a blow.\n",
      "case 340, 1:\n",
      "human text: I couldn ' t stand to be without my legs .\n",
      "LLM output: I couldn't stand without my legs.\n",
      "case 340, 2:\n",
      "human text: The two inventors of the radio were on the same wavelength .\n",
      "LLM output: Radio inventors had a wavelength to share.\n",
      "case 340, 3:\n",
      "human text: OLD HOCKEY PLAYERS never die , they just achieve their final goal .\n",
      "LLM output: The HOCKEY players were dying to reach the goal.\n",
      "case 340, 4:\n",
      "human text: The guitarist passed out on stage , he must have rocked himself to sleep .\n",
      "LLM output: The guitarist passed out after rocking all night long.\n",
      "case 340, 5:\n",
      "human text: Decimals have a point .\n",
      "LLM output: He had his point about the decimals.\n",
      "case 340, 6:\n",
      "human text: For the orthodontist visit , the boy had to brace himself .\n",
      "LLM output: The braces had been placed to brace myself.\n",
      "case 340, 7:\n",
      "human text: OLD SOCCER PLAYERS never die , they just achieve their final goal .\n",
      "LLM output: The soccer players celebrated their goal with a grand celebration.\n",
      "case 340, 8:\n",
      "human text: Police can do a search if it ' s Warranted .\n",
      "LLM output: The police searched the warrant.\n",
      "case 340, 9:\n",
      "human text: The correct formula for concrete is worthwhile to cement in your mind .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 341/810 [02:16<07:20,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The formula was the cement for their success.\n",
      "case 350, 0:\n",
      "human text: The inventor of the fahrenheit scale solved the problem by degrees .\n",
      "LLM output: A fahrenheit was reading degrees.\n",
      "case 350, 1:\n",
      "human text: My comb is invaluable - I can ' t part with it .\n",
      "LLM output: The valuable comb was part of my hair.\n",
      "case 350, 2:\n",
      "human text: If you don ' t know how to choose music ask a guitarist - they know how to pick .\n",
      "LLM output: I picked the right music and asked for a guitar pick.\n",
      "case 350, 3:\n",
      "human text: A city worker who campaigned for new sewer pipes finally had to go underground .\n",
      "LLM output: A city worker campaigned for underground access to the sewers.\n",
      "case 350, 4:\n",
      "human text: OLD SOCCER PLAYERS never die , they just go on dribbling .\n",
      "LLM output: The soccer player did not have any die to dribble.\n",
      "case 350, 5:\n",
      "human text: Marconi was not wired up about going .\n",
      "LLM output: Marconi's wireless communication system was wired to the radio station.\n",
      "case 350, 6:\n",
      "human text: OLD PROFESSORS never die , they just lose their class .\n",
      "Error parsing response: Unterminated string starting at: line 1 column 14 (char 13)\n",
      "LLM output: Error: Unable to parse response : {e}\n",
      "case 350, 7:\n",
      "human text: Pick your friends , but not to pieces\n",
      "LLM output: My friends picked my pocket.\n",
      "case 350, 8:\n",
      "human text: I bought a metronome for 20 bucks . You can ' t beat that price .\n",
      "LLM output: At the 20 bucks price, it was a bit of a beat.\n",
      "case 350, 9:\n",
      "human text: I can ' t really see myself without eyes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 351/810 [02:26<07:12,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: I don't see myself without eyes.\n",
      "case 360, 0:\n",
      "human text: The forecaster was away because he was under the weather .\n",
      "LLM output: The forecasters were under the weather again.\n",
      "case 360, 1:\n",
      "human text: The weigh - in at the Sumo wrestling tournament was a large scale effort .\n",
      "LLM output: The sumo weighs in at a large-scale effort.\n",
      "case 360, 2:\n",
      "human text: An elephant ' s opinion carries a lot of weight .\n",
      "LLM output: The elephant's opinion weighed heavily in the matter.\n",
      "case 360, 3:\n",
      "human text: Officer Jones takes his yearly bath every June . He is a characteristic example of a dirty cop .\n",
      "LLM output: An officer was soiled and a dirty year had been.\n",
      "case 360, 4:\n",
      "human text: OLD GUNS never die they just get loaded .\n",
      "LLM output: The old guns were still loaded and the shot was getting loaded.\n",
      "case 360, 5:\n",
      "human text: He put bug spray on his watch to get rid of the ticks .\n",
      "LLM output: I thought I'd take a little break and watch some bugs get rid of themselves.\n",
      "case 360, 6:\n",
      "human text: When you ' re wearing a watch on an airplane , time flies .\n",
      "LLM output: The watch said 'time flies'.\n",
      "case 360, 7:\n",
      "human text: Bowling Alley : Please be quiet . We need to hear a pin drop .\n",
      "LLM output: The bowling pin quietly pin'd down the quiet drop.\n",
      "case 360, 8:\n",
      "human text: Employers like their mechanics to be geared up .\n",
      "LLM output: The employers geared their mechanics to meet the demands.\n",
      "case 360, 9:\n",
      "human text: Lifes a ledger , are we giving a good accounting of ourselves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 361/810 [02:36<07:10,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: Lifes ledger was showing our own accounting.\n",
      "case 370, 0:\n",
      "human text: If you give some managers an inch they think they ' re a ruler .\n",
      "LLM output: Managers gave their employees rulers to think about their performance.\n",
      "case 370, 1:\n",
      "human text: The Transformer always had a lot of quarters with him . He was a big fan of change .\n",
      "LLM output: The transformer was changing its quarters.\n",
      "case 370, 2:\n",
      "human text: Whenever the nurses have a bad day they just keep needling people .\n",
      "LLM output: The nurses were needling people all day long.\n",
      "case 370, 3:\n",
      "human text: His day job was astronomy but at night time he was moonlighting .\n",
      "LLM output: I work as a night shift astronomer during my day job.\n",
      "case 370, 4:\n",
      "human text: I can ' t recall the last time I did any running , but I ' ve been jogging my memory .\n",
      "LLM output: I can't recall the last time I jogged.\n",
      "case 370, 5:\n",
      "human text: OLD SCULPTORS never die they just lose their marbles .\n",
      "LLM output: The sculptors lost their marbles.\n",
      "case 370, 6:\n",
      "human text: At seven foot six he was a great basketball player and everyone looked up to him .\n",
      "LLM output: I looked up at the basketball court and felt admiration for its size.\n",
      "case 370, 7:\n",
      "human text: OLD CASHIERS never die they just check out .\n",
      "LLM output: The cashier said the check was out.\n",
      "case 370, 8:\n",
      "human text: A church welcomed all denominations but preferred tens and twenties .\n",
      "LLM output: The church welcomed all denominations and preferred tens.\n",
      "case 370, 9:\n",
      "human text: OLD WRITERS never die , they just get erased .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 371/810 [02:45<06:56,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The writer's words were erased to death.\n",
      "case 380, 0:\n",
      "human text: The All - Pro wide receiver ' s wedding was a little bit shaky , but his reception was excellent .\n",
      "LLM output: The wide receiver caught the reception at the wedding.\n",
      "case 380, 1:\n",
      "human text: She was only a Real estate agent ' ' s daughter , but she gave a lot away .\n",
      "LLM output: Real estate agent 's gave a lot of land.\n",
      "case 380, 2:\n",
      "human text: Sure I can climb cliffs ! Tom bluffed .\n",
      "LLM output: The cliffs bluffed the brave.\n",
      "case 380, 3:\n",
      "human text: He was trying to sell me new windows , but his motivations were transparent .\n",
      "LLM output: The window was transparent to the motives behind the sales.\n",
      "case 380, 4:\n",
      "human text: It ' s OK to watch an elephant bathe as they usually have their trunks on .\n",
      "LLM output: An elephant has its trunks on.\n",
      "case 380, 5:\n",
      "human text: A small boy went to the counter to pay for his lunch but he was a little short .\n",
      "LLM output: The small boy was counter-paid for his goods.\n",
      "case 380, 6:\n",
      "human text: Those who want to paint polka - dots have to find a good spot .\n",
      "LLM output: The painter's polka dots were the stars of the show.\n",
      "case 380, 7:\n",
      "human text: If a clock had legs , time would run out .\n",
      "LLM output: Time is running out for me.\n",
      "case 380, 8:\n",
      "human text: The teacher asked a question and the students were all up in arms .\n",
      "LLM output: The teacher was up in arms over the question.\n",
      "case 380, 9:\n",
      "human text: Why are all businessmen fat ? Must be all the inflation .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 381/810 [02:54<06:42,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The businessmen must be feeling the inflation.\n",
      "case 390, 0:\n",
      "human text: He realized he ' d made the major leagues when it finally hit him .\n",
      "LLM output: A player was hit by a pitch and left the game.\n",
      "case 390, 1:\n",
      "human text: My new theory on inertia doesn ' t seem to be gaining momentum .\n",
      "LLM output: A theory was gaining momentum.\n",
      "case 390, 2:\n",
      "human text: I know a rancher who has 100 head of cattle , but he thought there were only 99 until he rounded them up .\n",
      "LLM output: The rancher thought only of rounding them up.\n",
      "case 390, 3:\n",
      "human text: A locksmith has to have a good Combination of skills .\n",
      "LLM output: The locksmith was able to combine his skills to solve the puzzle.\n",
      "case 390, 4:\n",
      "human text: Leonardo Da Vinci could use a paint brush to make a stroke of genius .\n",
      "LLM output: The genius of Da Vinci had painted his stroke on the wall.\n",
      "case 390, 5:\n",
      "human text: OLD ACTUARIES never die they just get broken down by age and sex .\n",
      "LLM output: An actuary died from the effects of being broken down by age and sex.\n",
      "case 390, 6:\n",
      "human text: Joe refused to eat sushi because it looks fishy .\n",
      "LLM output: Joe refused to eat sushi and it looked fishy.\n",
      "case 390, 7:\n",
      "human text: Did you hear about the tire dealer that had a blowout sale ?\n",
      "LLM output: A tire had blown out and the shop was having a blowout sale.\n",
      "case 390, 8:\n",
      "human text: ' ' This wind is awful , ' ' blustered Tom .\n",
      "LLM output: The president blustered and showed off.\n",
      "case 390, 9:\n",
      "human text: This is where I keep my arrows , said Tom , quivering .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 391/810 [03:04<06:40,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: The arrows were quivering in the breeze.\n",
      "case 400, 0:\n",
      "human text: So , how ' s the flower business going ? Oh , it ' s blossoming quite nicely .\n",
      "LLM output: The business is blossoming.\n",
      "case 400, 1:\n",
      "human text: Building a cul - de - sac would be a bit of a dead - end job .\n",
      "LLM output: The cul-de-sac at the end of my driveway was a dead end to me.\n",
      "case 400, 2:\n",
      "human text: Swimming instructors are always getting immersed in their work .\n",
      "LLM output: A swimming instructor immersed himself in the water and worked tirelessly.\n",
      "case 400, 3:\n",
      "human text: A dry cleaners had a dozen suits in court .\n",
      "LLM output: The dry cleaner couldn't find a suit that fit me.\n",
      "case 400, 4:\n",
      "human text: My student was late for class , claiming he was in the washroom . I think he was stalling .\n",
      "LLM output: The student claimed that he was in the washroom and might as well be in the stalling.\n",
      "case 400, 5:\n",
      "human text: We should make a beer commercial . It sounds simply intoxicating .\n",
      "LLM output: Beer commercials make us all sound intoxicating.\n",
      "case 400, 6:\n",
      "human text: They said he drank 2 bottles of whisky a day , but it wasn ' t true . He had to scotch those rumours right away .\n",
      "LLM output: A scotch bottle had become the center of a scotch rumor.\n",
      "case 400, 7:\n",
      "human text: She was only a Gardener ' s daughter , but she knows all the rakes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 400/810 [03:12<03:17,  2.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[103], line 2\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generation method 2\u001b[39;00m\n",
      "\u001b[0;32m----> 2\u001b[0m \u001b[43mcall_llm_to_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqwen2vl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqwen2vl_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_punDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhom_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      3\u001b[0m call_llm_to_generate(model\u001b[38;5;241m=\u001b[39mqwen2vl, model_name\u001b[38;5;241m=\u001b[39mqwen2vl_name, dataset\u001b[38;5;241m=\u001b[39mhet_punDataset, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, examples\u001b[38;5;241m=\u001b[39mhet_examples, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "Cell \u001b[0;32mIn[102], line 156\u001b[0m, in \u001b[0;36mcall_llm_to_generate\u001b[0;34m(model, dataset, model_name, method, examples, save, path_gen, batch_size)\u001b[0m\n",
      "\u001b[1;32m    145\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[1;32m    146\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n",
      "\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m    154\u001b[0m }\n",
      "\u001b[0;32m--> 156\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    157\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n",
      "\u001b[1;32m    105\u001b[0m \n",
      "\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n",
      "\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n",
      "\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n",
      "\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n",
      "\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n",
      "\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n",
      "\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n",
      "\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n",
      "\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n",
      "\u001b[1;32m    587\u001b[0m }\n",
      "\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n",
      "\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n",
      "\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n",
      "\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n",
      "\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n",
      "\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n",
      "\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n",
      "\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n",
      "\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n",
      "\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n",
      "\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n",
      "\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generation method 2\n",
    "call_llm_to_generate(model=qwen2vl, model_name=qwen2vl_name, dataset=hom_punDataset, method=2, examples=hom_examples, batch_size=10, save=True)\n",
    "call_llm_to_generate(model=qwen2vl, model_name=qwen2vl_name, dataset=het_punDataset, method=2, examples=het_examples, batch_size=10, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
